{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/erodola/DLAI-s2-2023/blob/main/labs/04/4_Logistic_Regression_and_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"4C5Ct9yoZKYa"},"source":["# Deep Learning & Applied AI\n","\n","# Tutorial 4: Logistic Regression and Optimization\n","\n","In this tutorial, we will cover:\n","\n","- Logistic regression\n","- Optimization, parameters tuning, weight decay, learning rate decay, loss landscape\n","\n","Based on original material by Dr. Luca Moschella, Dr. Antonio Norelli, and Dr. Marco Fumero.\n","\n","Course:\n","\n","- Website and notebooks will be available at https://github.com/erodola/DLAI-s2-2024/\n","\n","⚠️ **Compatibility warning:**\n","- For this notebook we are downgrading to plotly 5.11.0, because some plots stopped working with later versions. This is taken care of in the import dependencies cell below."]},{"cell_type":"markdown","source":["# Imports and utilities"],"metadata":{"id":"iXd3HJRDfLEO"}},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"pRePt-K1_yw9"},"outputs":[],"source":["# @title import dependencies\n","\n","!pip install plotly==5.11.0\n","\n","from typing import Mapping, Union, Optional, Tuple\n","\n","import numpy as np\n","import argparse\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import plotly.graph_objects as go\n","import torchvision\n","\n","from torchvision import datasets, transforms\n","from tqdm.notebook import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"2tGN_bJOcfd3"},"outputs":[],"source":["# @title reproducibility stuff\n","\n","import random\n","torch.manual_seed(42)\n","np.random.seed(42)\n","random.seed(0)\n","\n","torch.cuda.manual_seed(0)\n","torch.backends.cudnn.deterministic = True  # Note that this Deterministic mode can have a performance impact\n","torch.backends.cudnn.benchmark = False"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"bAaQr9d586Lv"},"outputs":[],"source":["# @title some non-convex functions we'll use\n","\n","from typing import Callable, Union, Sequence\n","import math\n","\n","def peaks(xx: torch.Tensor, yy: torch.Tensor) -> torch.Tensor:\n","  \"\"\"\n","  \"Peaks\" function that has multiple local minima.\n","  \"\"\"\n","  xx = torch.as_tensor(xx)\n","  yy = torch.as_tensor(yy)\n","  return (0.25 * (3*(1-xx)**2*torch.exp(-xx**2 - (yy+1)**2) -\n","                  10*(xx/5 - xx**3 - yy**5)*torch.exp(-xx**2-yy**2) -\n","                  1/3*torch.exp(-(xx+1)**2 - yy**2)))\n","\n","def rastrigin(xx: torch.Tensor, yy: torch.Tensor, shift: int = 0) -> torch.Tensor:\n","  \"\"\"\n","  \"Rastrigin\" function with `A = 3`\n","  https://en.wikipedia.org/wiki/Rastrigin_function\n","  \"\"\"\n","  xx = torch.as_tensor(xx)\n","  yy = torch.as_tensor(yy)\n","  A = 3\n","  return A * 2 + (((xx - shift) ** 2 - A * torch.cos(2 * torch.tensor(math.pi, dtype=torch.float, device=xx.device) * xx))\n","                  +\n","                  ((yy - shift) ** 2 - A * torch.cos(2 * torch.tensor(math.pi, dtype=torch.float, device=xx.device) * yy)))\n","\n","def rosenbrock(xx: torch.Tensor, yy: torch.Tensor) -> torch.Tensor:\n","  \"\"\"\n","  \"Rosenbrock\" function\n","  https://en.wikipedia.org/wiki/Rosenbrock_function\n","\n","  It has a global minimum at $(x , y) = (a, a^2) = (1, 1)$\n","  \"\"\"\n","  xx = torch.as_tensor(xx)\n","  yy = torch.as_tensor(yy)\n","\n","  a = 1\n","  b = 100\n","  return (a - xx) ** 2 + b * (yy - xx**2)**2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6VsXnIyGLsgb","cellView":"form"},"outputs":[],"source":["# @title utility functions for plotting\n","\n","\n","def plot_landscape(\n","    fn: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n","    resolution: int = 100,\n","    lim: int = 3,\n","    height: int = 900,\n","    landscape_opacity: float = 1.0,\n","    title: Optional[str] = None,\n","    autoshow: bool = False,\n","    xaxis_title=\"x\",\n","    yaxis_title=\"y\",\n","    zaxis_title = None,\n","    **kwargs\n",") -> go.Figure:\n","    \"\"\" Plot the landscape defined by the universal function `fn`.\n","\n","    Creates a domain grid $x,y \\in R^2$ with $x \\in [-lim, lim]$ and\n","    $y \\in [-lim, lim]. The number of points in this grid is resolution**2.\n","    \"\"\"\n","    xx = torch.linspace(-lim, lim, resolution)\n","    yy = torch.linspace(-lim, lim, resolution)\n","    zz = fn(xx[None, :], yy[:, None], **kwargs)\n","\n","    xx = xx.cpu().detach()\n","    yy = yy.cpu().detach()\n","    zz = zz.cpu().detach()\n","\n","    fig = go.Figure(data=[go.Surface(z=zz, x=xx, y=yy, opacity=landscape_opacity)])\n","    fig.update_traces(\n","        contours_z=dict(\n","            show=True, usecolormap=True, highlightcolor=\"lightgray\", project_z=True\n","        )\n","    )\n","    fig.update_layout(\n","        title=f\"{fn.__name__.title()} landscape\" if title is None else title,\n","        height=height,\n","        scene=dict(\n","            xaxis_title=xaxis_title,\n","            yaxis_title=yaxis_title,\n","            zaxis_title=f\"{fn.__name__}(x, y)\" if zaxis_title is None else zaxis_title,\n","        ),\n","    )\n","\n","    if autoshow:\n","      fig.show()\n","    return fig\n","\n","\n","def plot_point_over_landscape(\n","    fn: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n","    point: Tuple[float, float] = None,\n","    resolution: int = 100,\n","    lim: int = 3,\n","    landscape_opacity: float = 1.0,\n","    height: int = 900,\n","    title: Optional[str] = None,\n","    xaxis_title=\"x\",\n","    yaxis_title=\"y\",\n","    zaxis_title = None,\n","    autoshow: bool = False,\n",") -> go.Figure:\n","    \"\"\" Plot a point over the landascape defined by the cunction `fn`\n","\n","  :param fn: a universal function $R^2 -> R$\n","  :param point: if not None, marks the point with a red dot\n","  :param title: the title of the plots, if None defaults to  the fn name\n","  :param autoshow: if True, calls fig.show() before returning the figure\n","\n","  :retuns: the figure that contains the plot\n","  \"\"\"\n","    fig = plot_landscape(\n","        fn,\n","        resolution=resolution,\n","        lim=lim,\n","        height=height,\n","        landscape_opacity=landscape_opacity,\n","        title=title,\n","        xaxis_title=xaxis_title,\n","        yaxis_title=yaxis_title,\n","        zaxis_title=zaxis_title,\n","    )\n","\n","    # Create starting path\n","    x_point, y_point = (float(p) for p in point)\n","    fig.add_trace(\n","        go.Scatter3d(\n","            visible=True,\n","            showlegend=False,\n","            mode=\"markers\",\n","            marker=dict(size=6, color=\"white\", symbol=\"circle\"),\n","            x=[x_point],\n","            y=[y_point],\n","            z=[fn(x_point, y_point).cpu().detach()],\n","        )\n","    )\n","\n","    if autoshow:\n","        fig.show()\n","\n","    return fig\n","\n","\n","# awesome functions 👀\n","\n","\n","def plot_path_over_landscape(\n","    fn: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n","    x_path: Union[torch.Tensor, Sequence[float]],\n","    y_path: Union[torch.Tensor, Sequence[float]],\n","    global_minimum: Tuple[float, float] = None,\n","    resolution: int = 100,\n","    lim: int = 3,\n","    height: int = 900,\n","    landscape_opacity: float = 1.0,\n","    title: Optional[str] = None,\n","    xaxis_title=\"x\",\n","    yaxis_title=\"y\",\n","    zaxis_title = None,\n","    autoshow: bool = False,\n",") -> go.Figure:\n","    \"\"\" Plot a path over the landascape defined by the cunction `fn`\n","\n","  :param fn: a universal function $R^2 -> R$ (must support broadcasting between x, y)\n","  :param x_path: the x coordinate of each point in the path\n","  :param y_path: the y coordinate of each point in the path\n","  :param global_minimum: if not None, marks the point with a red dot\n","  :param resolution: the resolution of the R^2 domain\n","  :param lim: the limits of the R^2 domain (symmetric around 0 in x and y)\n","  :param height: the height of the figure\n","  :param landscape_opacity: the landscape plot opacity\n","  :param title: the title of the plots, if None defaults to  the fn name\n","  :param autoshow: if True, calls fig.show() before returning the figure\n","\n","  :retuns: the figure that contains the plot\n","  \"\"\"\n","    fig = plot_landscape(\n","        fn,\n","        resolution=resolution,\n","        lim=lim,\n","        height=height,\n","        landscape_opacity=landscape_opacity,\n","        title=title,\n","        xaxis_title=xaxis_title,\n","        yaxis_title=yaxis_title,\n","        zaxis_title=zaxis_title,\n","    )\n","\n","    x_path = torch.as_tensor(x_path, dtype=torch.float)\n","    y_path = torch.as_tensor(y_path, dtype=torch.float)\n","    z_path = fn(x_path, y_path)\n","\n","    # Create starting path\n","    fig.add_trace(\n","        go.Scatter3d(\n","            visible=True,\n","            showlegend=False,\n","            marker=dict(size=4, color=\"white\", symbol=\"circle\"),\n","            line=dict(color=\"lightgray\", width=3),\n","            x=x_path[0:1],\n","            y=y_path[0:1],\n","            z=z_path[0:1],\n","        )\n","    )\n","    # If you find out how to project the path onto the landscape contour, tell us! :]\n","\n","    if global_minimum is not None:\n","        x_point, y_point = (float(p) for p in global_minimum)\n","\n","        # Create the goal marker\n","        fig.add_trace(\n","            go.Scatter3d(\n","                visible=True,\n","                showlegend=False,\n","                mode=\"markers\",\n","                marker=dict(size=3, color=\"red\", symbol=\"circle\"),\n","                x=[x_point],\n","                y=[y_point],\n","                z=[fn(x_point, y_point).cpu().detach()],\n","            )\n","        )\n","\n","    # Create frames that modify the starting path\n","    frames = []\n","    for j in np.arange(1, z_path.shape[0]):\n","        frames.append(\n","            go.Frame(\n","                name=f\"frame{j}\",\n","                traces=[1],\n","                data=[go.Scatter3d(x=x_path[:j], y=y_path[:j], z=z_path[:j],)],\n","            )\n","        )\n","\n","    # Create the slider to start the animation at different timesteps\n","    sliders = [\n","        dict(\n","            steps=[\n","                dict(\n","                    method=\"animate\",  # Sets the Plotly method to be called when the\n","                    # slider value is changed.\n","                    args=[\n","                        [f\"frame{k}\"],  # Sets the arguments values to be passed to\n","                        # the Plotly method set in method on slide\n","                        dict(\n","                            mode=\"immediate\",\n","                            frame=dict(duration=50, redraw=False),\n","                            transition=dict(duration=0),\n","                        ),\n","                    ],\n","                    label=f\"{k}\",\n","                )\n","                for k in range(z_path.shape[0] - 1)\n","            ],\n","            currentvalue={\"prefix\": \"Iteration: \"},\n","        )\n","    ]\n","    # If you find out how to fix the slider let us know :]\n","\n","    fig[\"layout\"][\"sliders\"] = sliders\n","    fig[\"layout\"][\"updatemenus\"] = [\n","        dict(\n","            type=\"buttons\",\n","            pad={\"r\": 10, \"t\": 70},\n","            showactive=False,\n","            buttons=[\n","                dict(\n","                    label=\"Play\",\n","                    method=\"animate\",\n","                    args=[\n","                        None,\n","                        dict(\n","                            frame=dict(duration=500, redraw=True),\n","                            transition=dict(duration=0),\n","                            fromcurrent=True,\n","                            mode=\"immediate\",\n","                        ),\n","                    ],\n","                ),\n","                dict(\n","                    label=\"Pause\",\n","                    method=\"animate\",\n","                    args=[[None], dict(mode=\"immediate\")],\n","                ),\n","            ],\n","        )\n","    ]\n","\n","    fig[\"frames\"] = frames\n","\n","    if autoshow:\n","        fig.show()\n","\n","    return fig\n","\n","\n","def plot_optimization(\n","    fn: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n","    start: Tuple[float, float],\n","    opt: torch.optim.Optimizer,\n","    opt_args: Mapping[str, Union[float, str]],\n","    n_steps: int = 50,\n","    goal: Tuple[float, float] = None,\n","    device: Optional[str] = None,\n","    resolution: int = 100,\n","    lim: int = 3,\n","    height: int = 900,\n","    landscape_opacity: float = 1.0,\n","    title: Optional[str] = None,\n","    autoshow: bool = False,\n",") -> go.Figure:\n","    \"\"\"\n","    Run an optimization process and plot the optimization path\n","\n","    :param fn: a universal function $R^2 -> R$ (must support broadcasting between x, y)\n","    :param start: the starting point to optimize\n","    :param opt: the optimizer to use\n","    :param opt_args: the arguments to use for the current optimizers\n","    :param n_steps: the number of steps to perform in this optimization process\n","    :param goal: if not None, mark the point that represents the goal of the optimization\n","    :param device: the device to use, if None defaults to 'cuda' if available\n","    :param resolution: the resolution of the R^2 domain\n","    :param lim: the limits of the R^2 domain (symmetric around 0 in x and y)\n","    :param height: the height of the figure\n","    :param landscape_opacity: the landscape plot opacity\n","    :param title: the title of the plots, if None defaults to  the fn name\n","\n","    :param autoshow: if True, calls fig.show() before returning the figure\n","\n","    :returns: the figure with the landscape and the optimization path\n","    \"\"\"\n","    if device is None:\n","        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","    x = torch.tensor(start[0], device=device, dtype=torch.float, requires_grad=True)\n","    y = torch.tensor(start[1], device=device, dtype=torch.float, requires_grad=True)\n","    x_line = [x.cpu().detach().item()]\n","    y_line = [y.cpu().detach().item()]\n","\n","    opt = opt([x, y], **opt_args)\n","\n","    for i in tqdm(range(n_steps), desc=\"Optimization\"):\n","        out = fn(x, y)\n","        out.backward()\n","        opt.step()\n","        opt.zero_grad()\n","        x_line.append(x.item())\n","        y_line.append(y.item())\n","\n","    f = plot_path_over_landscape(\n","        fn,\n","        x_line,\n","        y_line,\n","        global_minimum=goal,\n","        resolution=resolution,\n","        lim=lim,\n","        height=height,\n","        landscape_opacity=1,\n","        title=title,\n","        autoshow=autoshow,\n","    )\n","    return f\n"]},{"cell_type":"markdown","metadata":{"id":"UvrnMPqEi8tH"},"source":["# Logistic Regression"]},{"cell_type":"markdown","metadata":{"id":"s00hN6W4k2HR"},"source":["### Classifying handwritten digits\n","Today we start with the *Hello world!* of deep learning, classifying MNIST digits using logistic regression."]},{"cell_type":"markdown","source":["## Data loading"],"metadata":{"id":"qb6JXFrQftIE"}},{"cell_type":"markdown","source":["We can either download the dataset ourselves, directly from Yann LeCun's website, or let the torchvision library do the job for us.\n","\n","Direct download would involve calling these functions:"],"metadata":{"id":"0sQkdQ5ngN1x"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"suK67C7figKY"},"outputs":[],"source":["# Here we are using a mirror for the official MNIST website\n","!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n","!tar -zxvf MNIST.tar.gz"]},{"cell_type":"markdown","source":["...and then you would have to put together a pytorch Dataset for training and test data and make sure it does what you wanted.\n","\n","Alternatively, we can use torchvision `datasets.MNIST`, which already inherits from torch `Dataset`, to do the job more quickly. Let's do that!"],"metadata":{"id":"2RBbrpyVNs33"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7gQwncVyrhql"},"outputs":[],"source":["train_dataset = datasets.MNIST(\n","    './',\n","    train=True,\n","    download=True,\n","    transform=transforms.Compose([\n","        # tranforming images to pytorch tensors\n","        transforms.ToTensor(),\n","\n","        # normalizing the tensors, i.e. the distribution of values on each sample should have mean=0.1307 and stddev=0.3081,\n","        # corresponding to the mean and stddev of the whole MNIST dataset.\n","        # Check https://stats.stackexchange.com/questions/211436/why-normalize-images-by-subtracting-datasets-image-mean-instead-of-the-current\n","        # for an intuition.\n","        transforms.Normalize((0.1307,), (0.3081,))\n","    ])\n",")\n","\n","test_dataset = datasets.MNIST('./', train=False,\n","                    transform=transforms.Compose([\n","                       transforms.ToTensor(),\n","                       transforms.Normalize((0.1307,), (0.3081,))\n","                   ])\n","                )"]},{"cell_type":"markdown","source":["## Data exploration"],"metadata":{"id":"_xpMqBAJfzyc"}},{"cell_type":"markdown","metadata":{"id":"c_qlZShtuFxx"},"source":["It is always a good idea to look at some entries in the dataset.\n","\n","**Note:** `train_dataset` and `test_dataset` are objects of the `torchvision.datasets.MNIST` class. Check the [docs](https://pytorch.org/vision/0.16/generated/torchvision.datasets.MNIST.html) to see how to use them!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fQPmyR30tKET"},"outputs":[],"source":["import plotly.express as px\n","import numpy as np\n","\n","mnist_example = train_dataset[42][0][0].numpy()\n","print('A MNIST sample has size', mnist_example.shape)\n","fig = px.imshow(mnist_example)\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"mmCGafsiuoLm"},"source":["**Is this a 1 or a 7?**\n","\n","This is the existential question we will try to answer today.\n","\n","Let's proceed by selecting only the 1 and 7 samples from the MNIST dataset.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gndHsV8413hO"},"outputs":[],"source":["for dataset in [train_dataset, test_dataset]:\n","    mask_sevens = dataset.targets == 7\n","    mask_ones = dataset.targets == 1\n","\n","    # re-map 7s to have label 0 and 1s to have label 1\n","    dataset.targets[mask_sevens] = 0\n","    dataset.targets[mask_ones] = 1\n","\n","    # only keep 7s and 1s\n","    dataset.targets = dataset.targets[mask_sevens + mask_ones]\n","    dataset.data = dataset.data[mask_sevens + mask_ones]"]},{"cell_type":"markdown","source":["Let's wrap the dataset in a pytorch DataLoader.\n","\n","Notice that by using `batch_size=len(dataset)`, each batch contains the entire dataset. This is not common, we are doing this here just because we don't really need smaller batches today."],"metadata":{"id":"ovE9sm_ZlY4Z"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"jE5OBK6QmcVf"},"outputs":[],"source":["train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"3rTgoLln13Eg"},"source":["\n","How difficult is this task?\n","\n",">It is always important to have an idea of how much *intelligence* you expect from your AI application.\n","\n","How can you make that estimate? Often a simple solution is at your fingertips...\n","\n",">**EXERCISE (warm-up)**: Combine several samples in a grid and plot a big picture. Then try to classify each one as a 1 or a 7, using your own judgement. What is your classification accuracy?\n","\n","Even the best spend their time classifying images by hand... ([Imagenet and Andrej Karpathy](http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/), director of AI at Tesla).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KW4JD8aEAxgf"},"outputs":[],"source":["# ✏️ your code here\n","# hint: use `torchvision.utils.make_grid` and `px.imshow`\n","\n","images = next(iter(train_dataloader))  # we only get one batch of data, since it contains the entire dataset\n","# ..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3iRguM45wQF8"},"outputs":[],"source":["# @title 👀 Solution  { run: \"auto\" }\n","\n","cols = 4  #@param {type:\"slider\", min:1, max:8, step:1}\n","rows = 3 #@param {type:\"slider\", min:1, max:4, step:1}\n","\n","grid_images = images[0][:rows*cols, ...]\n","resolved_grid = torchvision.utils.make_grid(grid_images, padding=4, nrow=cols, normalize=True, value_range=(0, 1))\n","px.imshow(resolved_grid.permute(1, 2, 0))"]},{"cell_type":"markdown","metadata":{"id":"9b-qUjGSzK1l"},"source":["## Building the model"]},{"cell_type":"markdown","source":["Given a dataset $(\\mathbf{X}, \\mathbf{t})$ where $\\mathbf{X} \\in \\mathbb{R}^{N \\times k}$ encodes $N$ data points and $\\mathbf{t} \\in [0,1]^N$ the corresponding ground-truth labels, the prediction of a logistic regression model with $\\theta = \\{\\mathbf{a}, b\\}$, on a sample $\\mathbf{x}_i$ is:\n","$$f_\\theta(\\mathbf{x}_i) = \\sigma(\\mathbf{a}^\\top\\mathbf{x}_i + b)\\,,$$\n","\n","with $\\sigma$ being the logistic sigmoid.\n","\n","Such predictions are evaluated by the following loss function, which we fully derived in class:\n","$$ E(\\theta) = - \\frac{1}{N}\\sum_{i=1}^N t_i \\ln(f_\\theta(\\mathbf{x}_i)) + (1 - t_i)\\ln(1 - f_\\theta(\\mathbf{x}_i)) $$\n","\n","This loss is commonly called **cross-entropy error**. Familiarize with this term, because it appears all the time!\n","\n","We are going to minimize the loss by following the opposite direction of the gradient of $E(\\theta)$, starting from an initial configuration $\\theta_0$. Recall that the gradient is defined as:\n","\n","$$\\nabla E(\\theta) = (\\frac{\\partial E}{\\partial a_1}, \\frac{\\partial E}{\\partial a_2}, ... , \\frac{\\partial E}{\\partial a_k}, \\frac{\\partial E}{\\partial b})$$\n","\n","Note that the logistic regression model we defined above, expects the data points $\\textbf{x}_i$ to be $k$-dimensional vectors. We can fit this format by flattening each image to a simple vector:\n","\n","![polyfit matrix notation](https://drive.google.com/uc?export=view&id=1uPlydRr82rgjd7pr04aBXl8SwEgrwK7I)\n","\n","We do this [with great reluctance](https://i.pinimg.com/originals/bd/a5/ef/bda5ef59a353d077c07a2f154f9c595a.jpg), because the flattening operation won't allow us to take advantage of patterns that are simple in 2D but become very intricate in 1D, making learning harder. When we'll reach CNNs, we'll see how image structure actually forms a strong prior for learning!"],"metadata":{"id":"Qn_Ku3oYgLjd"}},{"cell_type":"markdown","metadata":{"id":"wno25CI-aH-z"},"source":["Let's compute the predictions of our logistic regression model for a set of samples $\\mathbf{X}$, and also the gradient $\\nabla E(\\theta)$ .\n","\n",">**EXERCISE**: Complete the function below. The input to the function is a tensor `theta` of parameters (e.g., resulting from a previous iteration of gradient descent), the data points stored in a matrix `X`, and the ground-truth labels `t` for each data point.\n",">\n","> Recall that the prediction for a given data point is just a _scalar_, i.e. its predicted class."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YIBPNQ-IxTKU"},"outputs":[],"source":["# ✏️ your code here\n","\n","def lr_predictions_and_gradient(theta, X, t):\n","    \"\"\"\n","    Logistic regression predictions and gradient on MNIST\n","    Arguments:\n","    theta -- parameters, a torch tensor of size (28 * 28 + 1), the last is the bias\n","    X -- data, a torch tensor of size (number of examples, 28, 28)\n","    t -- true \"label\" vector (containing 0 if seven, 1 if one), a torch tensor of size (number of examples)\n","\n","    Return:\n","    loss -- negative log-likelihood loss, a torch tensor of size (1)\n","    dtheta -- gradient of the loss with respect to theta, a torch tensor of size (28 * 28 + 1)\n","    pred -- model predictions, a torch tensor of size (number of examples)\n","    \"\"\"\n","\n","    # GENERAL IDEA:\n","    #\n","    # Start by computing the loss.\n","    #\n","    # First think of how you would write the loss for one sample, then extend the computation\n","    # to all other samples _without_ using a for loop. It's just simple matrix operations.\n","    #\n","    # Recall that you don't have to return only the loss, but also all the predicted classes.\n","    #\n","    # For the gradient, don't make it harder than necessary: it's a simple formula, really.\n","\n","    # Predictions (from X to loss)\n","    # hint: add a column of ones to X to manage the bias\n","\n","\n","    # Gradient\n","\n","    assert dtheta.shape == theta.shape\n","\n","    return loss, dtheta, pred\n","\n","\n","# # testing the function, you should obtain loss = 1.127, torch.sum(gradient) = 57.592\n","# X, t = next(iter(train_dataloader))\n","# theta = torch.ones(28*28+1) / 100\n","\n","# loss, gradient, _ = lr_predictions_and_gradient(theta, X, t)\n","# print('loss:', loss, 'gradient:', torch.sum(gradient))"]},{"cell_type":"markdown","metadata":{"id":"1pVhm1ZM3w5b"},"source":["> [Math hint for the gradients](https://medium.com/mathematics-behind-optimization-of-cost-function/derivative-of-log-loss-function-for-logistic-regression-9b832f025c2d)  👀"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"wt1K5g-63fsc"},"outputs":[],"source":["# @title Solution 👀\n","\n","def lr_predictions_and_gradient(theta, X, t):\n","    \"\"\"\n","    Logistic regression predictions and gradient on MNIST\n","    Arguments:\n","    theta -- parameters, a torch tensor of size (28 * 28 + 1), the last is the bias\n","    X -- data, a torch tensor of size (number of examples, 28, 28)\n","    t -- true \"label\" vector (containing 0 if seven, 1 if one), a torch tensor of size (number of examples)\n","\n","    Return:\n","    loss -- negative log-likelihood loss, a torch tensor of size (1)\n","    dtheta -- gradient of the loss with respect to theta, a torch tensor of size (28 * 28 + 1)\n","    pred -- model predictions, a torch tensor of size (number of examples)\n","    \"\"\"\n","\n","    N = X.shape[0]\n","    X = X.reshape(N, -1)\n","\n","    # Predictions (from X to loss)\n","    # hint: add a column of ones to X to manage the bias\n","\n","    new_X = torch.cat((X, torch.ones((N, 1))), dim=1)\n","    pred = torch.sigmoid(torch.einsum('i,ji->j', theta, new_X)) # contains the (scalar) predictions for all data points\n","    loss = (- 1 / N) * torch.sum(t * torch.log(pred) + (1 - t) * (torch.log(1 - pred)))\n","\n","    # Gradient\n","    dtheta = (1 / N) * torch.einsum('ji,j->i', new_X, pred - t)\n","\n","    assert dtheta.shape == theta.shape\n","\n","    return loss, dtheta, pred\n","\n","\n","# testing the function, you should obtain loss = 1.127, torch.sum(gradient) = 57.592\n","X, t = next(iter(train_dataloader))\n","theta = torch.ones(28*28+1) / 100\n","\n","loss, gradient, _ = lr_predictions_and_gradient(theta, X, t)\n","print('loss:', loss, 'gradient:', torch.sum(gradient))"]},{"cell_type":"markdown","metadata":{"id":"_JcRld0z43cu"},"source":["####Optimizing the model\n","\n","We will search the optimal $\\theta$ through naive gradient descent (GD, $m = N$) and stochastic gradient descent (SGD, $m < N$).\n","$$\\theta^{(t+1)} = \\theta^{(t)} - \\alpha \\nabla E(\\theta^{(t)})$$\n","with\n","$$\\nabla E(\\theta^{(t)}) = \\frac{1}{m} \\sum_i^m \\nabla E_{\\theta^{(t)}}(\\{\\mathbf{x}_i, t_i\\}) $$\n","\n","We implemented SGD for you, so for the moment you can ignore the code below and just concentrate on the qualitative aspects.\n","\n","Feel free to play with two relevant parameters of the optimization:\n","- the batch size $m$.\n","- the number of *epochs*, each having $ \\frac{N}{m} $ steps  (A single step of naive GD is an epoch!)\n","\n","See how noisy the SGD training loss is, especially with small batch sizes. Why is that? Also look at the test loss!"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"vib7ijMV6YbQ"},"outputs":[],"source":["# @title Logistic regression: epochs and batch size (⚠️doesn't work with plotly >5.11.0) { run: \"auto\" }\n","\n","num_epochs = 9  #@param {type:\"slider\", min:1, max:20, step:1}\n","batch_size_1 = \"500\"  #@param [\"1\", \"2\", \"3\", \"5\", \"10\", \"50\", \"100\", \"500\", \"1000\", \"6500\", \"13007\"]\n","batch_size_2 = \"13007\"  #@param [\"1\", \"2\", \"3\", \"5\", \"10\", \"50\", \"100\", \"500\", \"1000\", \"6500\", \"13007\"]\n","plot_log_scale = False  #@param {type:\"boolean\"}\n","\n","learning_rate = 0.01\n","theta_init = torch.randn(28*28+1) / 100\n","\n","X, t = next(iter(train_dataloader))\n","X_test, t_test = next(iter(test_dataloader))\n","fig = go.Figure()\n","\n","for batch_size in [int(batch_size_1), int(batch_size_2)]:\n","    steps_per_epoch = int(X.shape[0] / batch_size)\n","    # X_slices = torch.chunk(X, steps_per_epoch)\n","    # t_slices = torch.chunk(t, steps_per_epoch)\n","    train_losses = []\n","    test_losses = []\n","    theta = theta_init\n","    print(f'Training with batch size: {batch_size}')\n","    for i in tqdm(range(num_epochs)):\n","        for j in range(steps_per_epoch):\n","            slice_batch = torch.arange((j * batch_size), ((j + 1) * batch_size), 1)\n","            train_loss, gradient, _ = lr_predictions_and_gradient(theta, X[slice_batch], t[slice_batch])\n","            theta = theta - learning_rate * gradient\n","            train_losses.append(train_loss.numpy())\n","\n","            test_loss, _, pred_test = lr_predictions_and_gradient(theta, X_test, t_test)\n","            test_losses.append(test_loss.numpy())\n","        if i % (int(num_epochs / 5) + 1) == 0:\n","            print(f'\\tEpoch {i}\\tTrain loss: {float(train_loss):.5f}\\tTest loss: {float(test_loss):.5f}')\n","\n","    test_accuracy = float(100 - torch.mean(torch.abs(pred_test - t_test)) * 100)\n","    print(f'\\tFinal test accuracy: {test_accuracy:.2f} %')\n","\n","    x = np.arange(num_epochs * steps_per_epoch) / steps_per_epoch * 100\n","    fig.add_trace(go.Scatter(x=x, y=train_losses, name=f'training loss, bs: {batch_size}'))\n","    fig.add_trace(go.Scatter(x=x, y=test_losses, name=f'test loss, bs: {batch_size}'))\n","\n","fig.update_layout(title='Loss per epoch', xaxis_title='100 * epoch', yaxis_title='loss')\n","if plot_log_scale:\n","    fig.update_xaxes(type=\"log\")\n","\n","fig.show()  # for some reason this doesn't work with plotly >5.11.0!"]},{"cell_type":"markdown","source":["### Code take-aways\n","\n","Time to peek into that code! Open the code cell above and look for the parts where we do the following:\n","\n","- We initialize GD/SGD with **random parameters**.\n","- The difference between GD and SGD is only in **the batch size**!\n","- With SGD, we slice the data tensor to **only compute $m$ gradients**; this makes it way more efficient!"],"metadata":{"id":"K5F5WCHfDbCN"}},{"cell_type":"markdown","source":["### Visualizing the weights\n","\n","Did you notice that we have as many weights as we have pixels in our image? Recall the logistic regression model:\n","\n","$$f_\\theta(\\mathbf{x}_i) = \\sigma(\\mathbf{a}^\\top\\mathbf{x}_i + b)\\,,$$\n","\n","This suggests that we can reshape the set of weights (just the $\\mathbf{a}$) as an image, and have a look at them!"],"metadata":{"id":"1IZqaV167pDQ"}},{"cell_type":"code","source":["px.imshow(theta[:-1].reshape(28, 28))"],"metadata":{"id":"j06n2dB81nh2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Can you read the image?"],"metadata":{"id":"j1KcaKVG_KWn"}},{"cell_type":"markdown","metadata":{"id":"U2eKSdGZCqXc"},"source":["### Optimal batch size\n","\n","Although with GPUs we can compute almost $K$ gradients $\\nabla E_{\\theta^{(t)}}(\\{\\mathbf{x}_i, t_i\\})$ at the same speed of a single gradient $\\nabla E_{\\theta^{(t)}}(\\{\\mathbf{x}_i, t_i\\})$ (as long as the samples $(\\{\\mathbf{x}_1, t_1\\}, ... , \\{\\mathbf{x}_K, t_K\\})$ fit in the GPU memory), generally in deep learning you do not want mini-batches to be too large.\n","\n","$$\n","\\text{You want a noisy approximation of the gradients.}\n","$$\n","\n","$$\n","\\text{You do not want to reach the global minimum of the loss.}\n","$$\n","\n","In fact, at the global minimum, an overparametrized model like a deep neural network would overfit big time.\n","\n"," Quoting the work of Keskar et al. [*On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima*](https://ar5iv.org/abs/1609.04836):\n","\n",">The stochastic gradient descent (SGD) method and its variants are algorithms of choice for many Deep Learning tasks. These methods operate in a small-batch regime wherein a fraction of the training data, say 32-512 data points, is sampled to compute an approximation to the gradient. It has been observed in practice that when using a larger batch there is a degradation in the quality of the model, as measured by its ability to generalize. We investigate the cause for this generalization drop in the large-batch regime and present numerical evidence that supports the view that large-batch methods tend to converge to sharp minimizers of the training and testing functions - and as is well known, sharp minima lead to poorer generalization. In contrast, small-batch methods consistently converge to flat minimizers, and our experiments support a commonly held view that this is due to the inherent noise in the gradient estimation.\n","\n","Nevertheless, the optimal size of a mini-batch is still debated and many interesting works have been published in the last years, for instance:\n","\n","- [*Don't Decay the Learning Rate, Increase the Batch Size*](https://ar5iv.org/abs/1711.00489)\n","- [*Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour*](https://arxiv.org/abs/1706.02677)"]},{"cell_type":"markdown","metadata":{"id":"h71mh066FQ0K"},"source":["#### Misclassified samples\n","Another good practice is to look for the samples where your trained model fails. Do you spot some trends?\n","\n","*In this test, we use the model trained with the value of `batch_size_2` set in the previous cell. Run that part again before running this test.*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"68CCE6_L8gKF"},"outputs":[],"source":["X_test, t_test = next(iter(test_dataloader))\n","\n","counter = 0\n","num_examples = 5  #@param {type:\"slider\", min:1, max:50, step:1}\n","for i in range(X_test.shape[0]):\n","    loss, _, pred = lr_predictions_and_gradient(theta, X_test[i], t_test[i])\n","    if loss > 1:  # let's plot misclassified samples only\n","        counter += 1\n","        print(f'sample {i}\\tprediction: {float(pred):.2f}\\tground truth: {t_test[i]}')\n","        fig = px.imshow(X_test[i][0].numpy())\n","        fig.update_layout(width=100, height=100, margin=dict(l=10, r=10, b=10, t=10))\n","        fig.update_xaxes(showticklabels=False).update_yaxes(showticklabels=False)\n","        fig.show()\n","        if counter == num_examples:\n","            break"]},{"cell_type":"markdown","metadata":{"id":"0MD2q9LEMaQw"},"source":["It would be nice being able to do tests more quickly, so that we don't have to wait forever for any little change we bring to our hyper-parameters such as the batch size!\n","\n","Being faster is crucial with larger models and datasets. Let's take a look at the tools of the trade."]},{"cell_type":"markdown","metadata":{"id":"5LaIS0vU9QBj"},"source":["# Optimization\n","\n"]},{"cell_type":"markdown","source":["In this section you will learn how different GD-based optimizers and their parameters drastically change the optimization process, both in speed and convergence.\n","\n","When looking for a minimum of a function $f$, a GD-based optimizer explores different configurations of parameters $x$, starting from a point $x^{(0)}$ and using only the *local* information provided by the gradients $\\nabla f (x^{(t)})$.\n","\n","As seen in the previous lesson (or the next one), the next configuration $x^{(t+1)}$ explored by all the common optimizers (e.g. SGD, RMSprop, Adam, ...) can be written as:\n","\n","$$\n","x^{(t+1)} = x^{(0)} + \\alpha \\sum_{i=0}^{t} \\Gamma_i^t  \\nabla f (x^{(t)})\n","$$\n","\n","We have:\n","\n","- $\\alpha$ the learning rate hyperparameter, i.e. how much the gradients should be magnified.\n","- $\\Gamma$ the momentum hyperparameter, i.e. how much the past gradients should be considered.\n"],"metadata":{"id":"kfpJmZZFhDQF"}},{"cell_type":"markdown","metadata":{"id":"H0bauc84HDZI"},"source":["## Context\n","\n","Deep learning involves **non-linear optimization**.\n","\n","In this section you will explore GD-based optimizers and their parameters on simple non-parametric functions $f: \\mathbb{R}^2 \\to \\mathbb{R}$ .\n","\n","Let's see an example (click on `play` -- ⚠️doesn't work with plotly >5.11.0):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4I4hb2RuMsGX"},"outputs":[],"source":["plot_optimization(fn=peaks, start=(0.0, 1.2), opt=torch.optim.Adam, opt_args={'lr': 0.75})"]},{"cell_type":"markdown","metadata":{"id":"N5yT0fptmAbI"},"source":["## A step-by-step example\n","\n","Let's take a look at how we can perform this kind of optimizations in PyTorch.\n"]},{"cell_type":"markdown","metadata":{"id":"WoNWiVTMml6b"},"source":["We are going to **define an arbitrary function** $f: \\mathbb{R}^2 \\to \\mathbb{R}$ and **a starting point** for our optimization:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jqABV6HnoCIK"},"outputs":[],"source":["# Define an arbitrary function\n","def fancy_function(xx: torch.Tensor, yy: torch.Tensor):\n","  xx = torch.as_tensor(xx)\n","  yy = torch.as_tensor(yy)\n","  return -torch.cos(xx) + torch.sin(yy) +  0.1 * (xx**2 + 2*yy**2)\n","\n","# Define a starting point\n","start = (-4, 4)"]},{"cell_type":"markdown","source":["The function returns a rank-0 PyTorch tensor, not a built-in python scalar! This is important, because we'll have to call PyTorch methods on it."],"metadata":{"id":"GWQuTvXMbLow"}},{"cell_type":"code","source":["out = fancy_function(start[0], start[1])\n","out.shape"],"metadata":{"id":"CRuNbKumbJNI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's now visualize our function and the starting point."],"metadata":{"id":"4xqEDM4EbjtA"}},{"cell_type":"code","source":["plot_point_over_landscape(fancy_function, point=start, lim=5, height=750)"],"metadata":{"id":"vgjNej-wbdUG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CVgjkHqEsfpz"},"source":["### Simple gradient descent: introducing `requires_grad` and `backward()`"]},{"cell_type":"markdown","metadata":{"id":"hPojrdQ9mc-x"},"source":["Now we want to make point $p$ descend the $f$ landscape.\n","\n","We can easily do this with some ready-made optimizers in `torch.nn.optim`. However, just for this example, we are going to **implement our own gradient descent**.\n","\n","With this excuse, we'll introduce a key method that will help us compute gradients automagically🪄: the `backward()` method.\n","\n","Once we have our gradients ready, we will apply gradient updates to the starting point, and so on for each iteration. We need to choose:\n","\n","- The learning rate $\\alpha$\n","- How many steps we want to execute (alternatively, we could check for convergence)."]},{"cell_type":"markdown","source":["\n",">**NOTE:** We must explicitly tell PyTorch that we'll compute gradients with respect to the starting point! If `t` is our tensor containing the parameters, we use `requires_grad=True` to tell PyTorch that at some point in our code we will need the gradient of the loss w.r.t. to `t`.\n",">\n","> In the next theory class you will learn *how* the gradient computation is done, and in the next lab you will explore in detail the `autograd` package for automatic differentiation."],"metadata":{"id":"EryYVm5qXMM4"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q0I8StZsxCKY"},"outputs":[],"source":["n_steps = 50    # Number of steps\n","alpha = 3       # The learning rate\n","\n","\n","# The starting point, with requires_grad=True\n","x = torch.tensor(start[0], dtype=torch.float, requires_grad=True)\n","y = torch.tensor(start[1], dtype=torch.float, requires_grad=True)\n","\n","\n","# While the starting point descends towards the minimum, we want to remember\n","# each intermediate point, to visualize the path once the optimization ends.\n","# Thus, we define two variables to mantain the points (x(t),y(t)), and initialize\n","# them with the starting point.\n","x_path = [x.item()]\n","y_path = [y.item()]\n","\n","\n","# Manual implementation of a simple gradient descent: NOT what we'll use in the future!\n","for i in tqdm(range(n_steps), desc='Manual optimization'):\n","\n","  out = fancy_function(x, y)       # Get the current value of the function. 'out' is a rank-0 tensor.\n","\n","  out.backward()                   # 🪄Computes the partial derivatives and stores\n","                                   # them in x.grad and y.grad. More details next week!\n","\n","  # We are now going to explicitly update x and y with a GD step.\n","  # Clearly, we are not interested in computing the gradient *of the update operations themselves*.\n","  # It sounds obvious, but if we don't tell PyTorch, it will attempt to compute those derivatives!\n","  # We use the .no_grad() command to do so. More on this next week!\n","\n","  with torch.no_grad():            # Disable gradient computation since we are only updating the parameters\n","    x -= alpha * x.grad            # Do in-place update manually\n","    y -= alpha * y.grad            # Do in-place update manually\n","\n","    x.grad = None                  # Remember to reset the current gradient.\n","    y.grad = None                  # Otherwise, the next backward() call will accumulate the gradient with the previous one!\n","\n","  # Add the new point the the path\n","  x_path.append(x.item())\n","  y_path.append(y.item())\n","\n","\n","# Then, visualize how the starting point moved around the surface\n","plot_path_over_landscape(fn=fancy_function, x_path=x_path, y_path=y_path, lim=5)"]},{"cell_type":"markdown","metadata":{"id":"xpfC6MtSzj1a"},"source":["###### **EXERCISE**\n",">\n","> Did the optimization reach the minimum?\n",">\n","> Change the parameters to make the optimization process converge in less than `50` steps!"]},{"cell_type":"markdown","metadata":{"id":"8pbUkeGInqo6"},"source":["###### **EXERCISE**\n",">\n","> Implement the momentum mechanism in the previous gradient descent algorithm.\n",">\n","> *Note: Don't do this exercise if the theory class has not covered momentum yet.*"]},{"cell_type":"markdown","metadata":{"id":"QtGwWrVozyst"},"source":["##### PyTorch optimizers\n","\n","It's time to discover the `torch.optim` package to use famous optimizers such as `torch.optim.Adam`."]},{"cell_type":"markdown","metadata":{"id":"D5j6U1AddjbG"},"source":["Every PyTorch optimizer takes, as a first argument, a list of parameters to optimize (hence they must have `requires_grad=True`), plus other hyper-parameters specific to each optimizer, such as the `momentum`, `alpha` or `weight_decay`. They usually have sensible defaults.\n","\n","---\n","\n","⚠️ **Momentum *is not* weight decay**\n","\n","Some optimizers in PyTorch like `torch.optim.Adam` have a `weight_decay` parameter. However, if you look at the [docs](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html), you'll see that this decay is actually a $L_2$ penalty on the optimization parameters. _It's not a decay schedule for the learning rate_. If `weight_decay`$=\\lambda$, it's adding a term $\\lambda\\|\\theta\\|_2^2$ to the loss.\n","\n","One way to think about it is that weight decay *regularizes the function* that's being optimized, while momentum *regularizes the path* you take over it.\n","\n","The integration in the optimizers is a purely usability-driven choice by PyTorch developers.\n","\n","\n","---\n","\n","Let's use the Adam optimizer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HGVrr4h42AXx"},"outputs":[],"source":["# Reset the variables, otherwise we would have the starting point *in* the optimum\n","x = torch.tensor(start[0], dtype=torch.float, requires_grad=True)\n","y = torch.tensor(start[1], dtype=torch.float, requires_grad=True)\n","x_path = [x.item()]\n","y_path = [y.item()]\n","# -----------------\n","\n","lr = .5\n","adam = torch.optim.Adam([x, y], lr=lr)  # Instantiate the optimizer\n","\n","for i in tqdm(range(n_steps), desc='Adam optimization'):\n","  out = fancy_function(x, y)            # Get the current value of the function\n","  out.backward()                        # Compute the partial derivatives\n","  adam.step()                           # Perfom one optimization step with some fancy rule\n","  adam.zero_grad()                      # Set the all the parameters grad to zero\n","\n","  # Add the new point the the path\n","  x_path.append(x.item())\n","  y_path.append(y.item())\n","\n","\n","plot_path_over_landscape(fn=fancy_function, x_path=x_path, y_path=y_path, lim=5)"]},{"cell_type":"markdown","source":["**Tech tip:** In order to ease the reading and visualization in this notebook,\n","we decoupled the code that you just saw in the `plot_optimization` function. You can use it to plot the gradient descent paths on your own custom functions.\n","\n","The simplest call to this function is:\n","  ```python\n","  plot_optimization(fn = ...,       # A universal function R^2 -> R\n","                    start = ...,    # A starting point (x, y)\n","                    opt = ...,      # An optimizer class from torch.optim\n","                    opt_args = ..., # A dict with the optimizer hyperparameters\n","  ```\n","\n","It requires `fn` to be a _universal_ function, which in Numpy jargon is a function that supports broadcasting of its arguments. In our example, `fancy_function` is universal because it uses element-wise operations like `torch.cos`, `torch.sin` and `*`. Read more in the [docs](https://numpy.org/doc/stable/user/basics.ufuncs.html#ufuncs-basics).\n","\n","To read the whole docstring of `plot_optimization` just write:"],"metadata":{"id":"ELggno3CcU30"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9xrjJpVl2SGC"},"outputs":[],"source":["help(plot_optimization)"]},{"cell_type":"markdown","metadata":{"id":"bQPNQ7O6tgxB"},"source":["###### **EXERCISE**\n",">\n","> Define your own function and the starting point to optimize.\n",">\n","> 😈 *Be evil!* Make it so that the previous optimization with `Adam` and `lr=.5` does not converge easily.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S8LsXQuVwDzr"},"outputs":[],"source":["# Choose the starting point:\n","angry_point = (-2, 2)\n","\n","# Choose your function:\n","def angry_function(xx: torch.tensor, yy: torch.Tensor) -> torch.Tensor:\n","  \"\"\" My awesome function, do not change the name!\n","\n","  This must be a *universal* function: xx and yy may have different dimensions,\n","  but it must be possible to broadcast them together to perform the computation.\n","\n","  For example:\n","      OK: xx.shape is [3, 1] and yy.shape is [1, 4]\n","      KO: xx.shape is [3, 2] and yy.shape is [3, 3]\n","\n","  :param xx: one or more x coordinates\n","  :param yy: one or more y coordinates\n","\n","  :returns: f(x, y) for each couple (x, y), following the broacasting rules\n","  \"\"\"\n","  xx = torch.as_tensor(xx)\n","  yy = torch.as_tensor(yy)\n","\n","  output = -1/(1 + xx**2 + yy**2)  # Delete this line and invent your own function!\n","\n","  return output\n","\n","# plot_point_over_landscape(angry_function, point=angry_point, height=500)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E9_4Gqxawkj-"},"outputs":[],"source":["# Check how the optimization goes!\n","\n","plot_optimization(fn=angry_function, start=angry_point, opt=torch.optim.Adam, opt_args={'lr': 0.5})"]},{"cell_type":"markdown","metadata":{"id":"bLgvF66DrOqH"},"source":["## Playground: hyperparameter tuning\n","\n","In the following cell there are some optimization problems.\n","Play with the *number of steps*, *optimizer*, *learning rate* and *momentum*. How difficult is it to  reach the global minimum?\n","\n","You can read the details of each optimizer, together with the reference paper, in the [docs](https://pytorch.org/docs/stable/optim.html). This [page](https://github.com/jettify/pytorch-optimizer/blob/master/README.rst) contains an in-depth comparison of more exotic optimizers.\n","\n","*Note: not every optimizer will use the momentum parameter*"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"ciLWbS6I_SQ_"},"outputs":[],"source":["# @title Hyperparameter tuning { run: \"auto\" }\n","\n","from typing import Tuple\n","opt_info = {\n","    'SGD': (torch.optim.SGD, ['lr', 'momentum', 'weight_decay']),\n","    'RMSprop': (torch.optim.SGD, ['lr', 'momentum', 'weight_decay']),\n","    'Adagrad': (torch.optim.Adagrad, ['lr', 'weight_decay']),\n","    'Adam': (torch.optim.Adam, ['lr', 'weight_decay']),\n","    'AdamW': (torch.optim.Adagrad, ['lr', 'weight_decay']),\n","    'Adamax': (torch.optim.Adagrad, ['lr', 'weight_decay']),\n","}\n","\n","def print_info(steps: int,\n","               opt: str,\n","               opt_params: Mapping[str, Tuple[torch.optim.Optimizer, Sequence[str]]]\n",") -> None:\n","    print(f'Using {opt} for {steps} steps with: {\", \".join(\"=\".join(str(y) for y in x) for x in opt_params.items())}')\n","\n","def filter_params(params: Mapping,\n","                  opt_info: Mapping[str, Tuple[torch.optim.Optimizer, Sequence[str]]]\n",") -> None:\n","    return {x: params[x] for x in params if x in opt_info[opt][1]}\n","\n","opt = \"Adam\"       #@param [\"SGD\",  \"RMSprop\", \"Adagrad\", \"Adam\", \"AdamW\", \"Adamax\"]\n","steps = 20            #@param {type:\"slider\", min:0, max:200, step:5}\n","learning_rate = 0.20497 #@param {type:\"slider\", min:0, max:1, step:0.00001}\n","momentum = 0.24274      #@param {type:\"slider\", min:0, max:1.5, step:0.00001}\n","\n","show_peaks_function = False #@param {type:\"boolean\"}\n","show_angry_function = False #@param {type:\"boolean\"}\n","show_rosenbrock_function = False #@param {type:\"boolean\"}\n","show_rastrigin_function = True #@param {type:\"boolean\"}\n","plots_height = 700 #@param {type:\"slider\", min:0, max:1500, step:50}\n","plot_lim = 3  #@param {type:\"slider\", min:0, max:50, step:1}\n","\n","params = {\n","    'lr': learning_rate,\n","    'momentum': momentum\n","}\n","\n","opt_params = filter_params(params, opt_info)\n","print_info(steps, opt, opt_params)\n","\n","if show_peaks_function:\n","  plot_optimization(fn=peaks,\n","                    start=(0.25, 1.3),\n","                    opt=opt_info[opt][0],\n","                    opt_args=opt_params,\n","                    n_steps=steps,\n","                    autoshow=True,\n","                    lim=plot_lim,\n","                    height=plots_height,\n","                    )\n","\n","if show_angry_function:\n","  plot_optimization(fn=angry_function,\n","                    start=angry_point,\n","                    opt=opt_info[opt][0],\n","                    opt_args=opt_params,\n","                    n_steps=steps,\n","                    autoshow=True,\n","                    lim=plot_lim,\n","                    height=plots_height)\n","\n","if show_rosenbrock_function:\n","  plot_optimization(fn=rosenbrock,\n","                    start=(2,-2),\n","                    opt=opt_info[opt][0],\n","                    opt_args=opt_params,\n","                    goal=(1,1),\n","                    n_steps=steps,\n","                    autoshow=True,\n","                    lim=plot_lim,\n","                    height=plots_height)\n","\n","if show_rastrigin_function:\n","  plot_optimization(fn=rastrigin,\n","                    start=(-2.45, -2.45),\n","                    opt=opt_info[opt][0],\n","                    opt_args=opt_params,\n","                    n_steps=steps,\n","                    autoshow=True,\n","                    lim=plot_lim,\n","                    height=plots_height)"]},{"cell_type":"markdown","metadata":{"id":"2SfcOlmR3K4l"},"source":["## In-depth: weight decay\n","The optimization of the Rastrigin function is not **very stable**, right?\n","\n","Let's try again, with the possibility to tune the `weight_decay` regularizer in the optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"wb5etaoi3K4o"},"outputs":[],"source":["# @title Regularized [rastrigin](https://en.wikipedia.org/wiki/Rastrigin_function) function: weight decay { run: \"auto\" }\n","\n","\n","opt = \"Adam\"       #@param [\"SGD\",  \"RMSprop\", \"Adagrad\", \"Adam\", \"AdamW\", \"Adamax\"]\n","steps = 50            #@param {type:\"slider\", min:0, max:200, step:5}\n","learning_rate = 0.19322 #@param {type:\"slider\", min:0, max:1, step:0.00001}\n","momentum = 0.07454      #@param {type:\"slider\", min:0, max:1.5, step:0.00001}\n","weight_decay = 9.982 #@param {type:\"slider\", min:0, max:10, step:0.001}\n","plot_lim = 3  #@param {type:\"slider\", min:0, max:50, step:1}\n","\n","params = {\n","    'lr': learning_rate,\n","    'momentum': momentum,\n","    'weight_decay': weight_decay,\n","}\n","\n","opt_params = filter_params(params, opt_info)\n","print_info(steps, opt, opt_params)\n","\n","plot_optimization(fn=rastrigin,\n","                  start=(-2.45, -2.45),\n","                  opt=opt_info[opt][0],\n","                  opt_args=opt_params,\n","                  n_steps=steps,\n","                  lim=plot_lim)"]},{"cell_type":"markdown","metadata":{"id":"rdBaIrEU3K4w"},"source":["As you can see, the optimization is much easier when introducing the `weight_decay`!\n","\n","...how is that possible? It seems to defy gravitational laws (so to speak).\n","\n","\n","**Sometimes**, the $L_2$-regularized function is \"more convex\", thus, it helps the optimization! Keep in mind that the $L_2$ penalty is actually modifying the loss, making it smoother.\n","A common value for the `weight_decay` is `1e-5`.\n","\n","Let's try to visualize the regularized function that we're actually considering during the previous optimization *(remember, the weight decay changes the function being optimized, not the optimizer)*.\n","\n","In this example we will not use the `weight_decay` parameter of the optimizer, but we will apply the weight decay directly to the function; thus, we can visualize the function being optimized."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1s6uGblP3K4x"},"outputs":[],"source":["def regularized_rastrigin(xx, yy, weight_decay):\n","  xx = torch.as_tensor(xx)\n","  yy = torch.as_tensor(yy)\n","  oo = rastrigin(xx, yy)\n","\n","  return oo +  weight_decay*(xx**2 + yy**2)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"gYytGjrDuvqf"},"outputs":[],"source":["# @title Regularized [rastrigin](https://en.wikipedia.org/wiki/Rastrigin_function) function: weight decay { run: \"auto\" }\n","\n","from functools import partial\n","\n","opt = \"Adam\"       #@param [\"SGD\",  \"RMSprop\", \"Adagrad\", \"Adam\", \"AdamW\", \"Adamax\"]\n","steps = 50            #@param {type:\"slider\", min:0, max:200, step:5}\n","learning_rate = 0.19322 #@param {type:\"slider\", min:0, max:1, step:0.00001}\n","momentum = 0.07454      #@param {type:\"slider\", min:0, max:1.5, step:0.00001}\n","weight_decay = 3.945 #@param {type:\"slider\", min:0, max:10, step:0.001}\n","plot_lim = 3  #@param {type:\"slider\", min:0, max:50, step:1}\n","\n","params = {\n","    'lr': learning_rate,\n","    'momentum': momentum,\n","}\n","\n","opt_params = filter_params(params, opt_info)\n","print_info(steps, opt, opt_params)\n","\n","fn = partial(regularized_rastrigin, weight_decay=weight_decay)\n","fn.__name__ = 'Regularized rastrigin'\n","\n","plot_optimization(fn=fn,\n","                  start=(-2.45, -2.45),\n","                  opt=opt_info[opt][0],\n","                  opt_args=opt_params,\n","                  n_steps=steps,\n","                  lim=plot_lim)"]},{"cell_type":"markdown","metadata":{"id":"Nw-cGJ1KGCu7"},"source":["However, a strong regularization may **change too much** the function, making the global minimum disappear or new global minima appear.\n","\n","In the following example, we re-define Rastrigin to have its global minimum shifted to `(shift, shift)` (the white dot in the plot): increasing the `weight_decay` deforms the function by moving the global minimum back to `(0, 0)`!"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"4qmQsdD6GYu0"},"outputs":[],"source":["# @title Weight decay pitfalls { run: \"auto\" }\n","\n","def shifted_rastrigin(xx: torch.tensor, yy: torch.Tensor, weight_decay,shift: int) -> torch.Tensor:\n","  xx = torch.as_tensor(xx)\n","  yy = torch.as_tensor(yy)\n","  oo = rastrigin(xx, yy, shift)\n","\n","  return oo +  weight_decay*(xx**2 + yy**2)\n","\n","\n","weight_decay = 0.77 #@param {type:\"slider\", min:0, max:1, step:0.01}\n","shift = 5 #@param {type:\"slider\", min:0, max:50, step:1}\n","\n","plot_height = 400 #@param {type:\"slider\", min:0, max:1500, step:50}\n","plot_lim = 8  #@param {type:\"slider\", min:0, max:50, step:1}\n","\n","f = plot_point_over_landscape(lambda x, y: shifted_rastrigin(x, y, weight_decay=weight_decay, shift=shift),\n","                              point=(shift, shift),\n","                              height=plot_height,\n","                              autoshow=True,\n","                              title='Shifted Regularized Rastrigin with global minimum in (shift, shift)',\n","                              lim=plot_lim)"]},{"cell_type":"markdown","metadata":{"id":"DgTAQ-1v6DSb"},"source":["## Learning rate decay\n","\n","When using some optimizers it may be useful to introduce a _learning rate_ decay policy. The learning rate will not be fixed for each step but will vary at different timesteps $t$.\n","\n","Some optimizers also automatically adjust the learning rate (e.g. Adam)."]},{"cell_type":"markdown","metadata":{"id":"H7JDvp1_72X_"},"source":["PyTorch provides some easy-to-use classes to manage the decay policy. The [`torch.optim.lr_scheduler`](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate) package provides several methods to adjust the learning rate based on the number of epochs.\n","\n","Learning rate scheduling should be applied **after the optimizer’s update**; e.g., you should write your code this way:\n","\n","```python\n","scheduler = ...\n","for epoch in range(n_epochs):\n","    out = fn(...)\n","    out.backward()\n","    opt.step()\n","    opt.zero_grad()\n","    scheduler.step() # AFTER opt.step(): breaking change with PyTorch 1.1.0\n","```\n","\n","If you are also testing your model on a validation dataset during the training loop, this is how it should look:\n","\n","```python\n","scheduler = ...\n","for epoch in range(n_epochs):\n","    train(...)\n","    validate(...)\n","    scheduler.step()\n","```\n","\n","Examples of such policies are [`lr_scheduler.ExponentialLR`](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ExponentialLR.html#torch.optim.lr_scheduler.ExponentialLR) and [`lr_scheduler.CosineAnnealingLR`](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingLR.html#torch.optim.lr_scheduler.CosineAnnealingLR)\n","\n","Let's see the `ExponentialLR` in action!"]},{"cell_type":"markdown","metadata":{"id":"p7sI8nMa94n1"},"source":["This is a standard gradient descent optimization with **fixed learning rate**:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Y8bzMIQ9JiC"},"outputs":[],"source":["start = (-4, 4)\n","fn = fancy_function\n","n_steps = 50\n","lr = 2\n","plot_optimization(fn=fn,\n","                  start=start,\n","                  opt=torch.optim.SGD,\n","                  opt_args={'lr': lr},\n","                  lim=5,\n","                  n_steps=n_steps)"]},{"cell_type":"markdown","metadata":{"id":"RrAxM8w5-F6p"},"source":["This is the same optimization, but with the introduction of a **`ExponentialLR` decay policy**.\n","The `ExponentialLR` decay is simply a multiplicative decay: at each step the learning rate is multiplied by a `gamma` value."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pa4ZBrCS7LTQ"},"outputs":[],"source":["from torch.optim.lr_scheduler import ExponentialLR\n","from torch.optim import SGD\n","\n","x = torch.tensor(start[0], dtype=torch.float, requires_grad=True)\n","y = torch.tensor(start[1], dtype=torch.float, requires_grad=True)\n","x_line = [x.item()]\n","y_line = [y.item()]\n","\n","opt = SGD([x, y], lr =lr)\n","scheduler = ExponentialLR(opt, gamma=.8)  # Multiplicative factor of .8 for the learning rate decay\n","\n","for i in tqdm(range(n_steps), desc=\"Optimization\"):\n","    out = fn(x, y)\n","    out.backward()\n","    opt.step()\n","    opt.zero_grad()\n","\n","    scheduler.step()                      # Perform one step of lr decay. AFTER opt.step()\n","\n","    x_line.append(x.item())\n","    y_line.append(y.item())\n","\n","plot_path_over_landscape(fn, x_line, y_line, lim=5)"]},{"cell_type":"markdown","metadata":{"id":"O_UW943f3K46"},"source":["## ...back to learning"]},{"cell_type":"markdown","metadata":{"id":"iuzu9BCb3K47"},"source":["When we do deep learning, we want to minimize the _loss_.\n","\n","To be more precise, there are two functions at play:\n","- A parametric model $f_{\\theta}$ that we want to learn, meaning that we seek its optimal parameters $\\theta$.\n","- A loss function $\\ell$ telling us how well we are doing with our model.\n","\n","$$\n","\\underset{\\theta}{\\mathrm{argmin}} \\; \\mathrm{\\ell}(f_\\theta(\\mathbf{x}))\n","$$\n","\n","Here, $\\mathbf{x}$ is simply the data: it is given, and fixed.\n","\n","$f_\\theta$ and $\\ell$ play different roles in the optimization, and we can visualize the optimization process from their distinct points of view:\n","\n","- We can visualize how $f_{\\theta}$ changes over time, while the loss gets minimized.\n","- We can visualize directly how $\\ell$ gets minimized over time."]},{"cell_type":"markdown","source":[">💡**Sudden revelation**\n",">\n",">Since the loss is defined in terms of our learning model $f_\\theta$ (e.g., a neural network), it shouldn't be surprising that most of the gradient information of $\\nabla_\\theta\\ell$ is encoded in $f_\\theta$. This actually follows directly from the chain rule.\n",">\n",">In fact, [a very recent work](https://ar5iv.labs.arxiv.org/html/2312.04709) (as of 2024) showed that you can estimate the gradient of the loss... without knowing the loss! Here's a quote:\n",">\n","> >How much can you say about the gradient of a neural network without computing a loss or knowing the label? This may sound like a strange question: surely the answer is “very little.” However, in this paper, we show that gradients are more structured than previously thought. Gradients lie in a predictable low-dimensional subspace which depends on the network architecture and incoming features. Exploiting this structure can significantly improve gradient-free optimization schemes based on directional derivatives, which have struggled to scale beyond small networks trained on toy datasets.\n",">\n","> How cool is that?"],"metadata":{"id":"I4aIFQJQptPM"}},{"cell_type":"markdown","metadata":{"id":"HYt3yXVzjZDj"},"source":["We're now going to do some plots of $f_\\theta$ and $\\ell$.\n","\n","Let's define a parametric function $f_\\theta: \\mathbb{R}^2 \\to \\mathbb{R} \\; \\text{ with } \\theta \\in \\mathbb{R}^2$. We assume it will approximate some unknown function $\\widetilde{f}: \\mathbb{R}^2 \\to \\mathbb{R}$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YBs1nLa3vEvB"},"outputs":[],"source":["# Define an arbitrary parametric function. The parameters to learn are theta1, theta2.\n","def learnable_function(xx: torch.Tensor, yy: torch.Tensor, theta1: torch.Tensor, theta2: torch.Tensor):\n","  xx = torch.as_tensor(xx, dtype=torch.float)\n","  yy = torch.as_tensor(yy, dtype=torch.float)\n","  theta1 = torch.as_tensor(theta1, dtype=torch.float)\n","  theta2 = torch.as_tensor(theta2, dtype=torch.float)\n","  return (theta1 * theta2).sin() * (xx**2).cos()**2 / (1 + (theta2 * yy)**2)"]},{"cell_type":"markdown","metadata":{"id":"jUM8qc_bREUr"},"source":["Now say that we have a point $\\mathbf{p} \\in \\mathbb{R}^2$ and that we know the value of the unknown $\\widetilde{f}$ at $\\mathbf{p}$:\n","\n","$$\\widetilde{f}(\\mathbf{p}) = -1 $$\n","\n","This means that our dataset is composed of a single pair: $(\\mathbf{p}, \\widetilde{f}(\\mathbf{p}))$.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RsGGFR-oRi3g"},"outputs":[],"source":["p = (0, 0)\n","\n","ground_truth_fp = -1"]},{"cell_type":"markdown","source":["Let's initialize the learning process:"],"metadata":{"id":"5CDBEQ6dtGxI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wtL67TDEv4YL"},"outputs":[],"source":["# Define some initial theta weights for the function\n","theta1_value = 2\n","theta2_value = -2"]},{"cell_type":"markdown","metadata":{"id":"WCR39NVReajN"},"source":["Finally, let's plot **$f_\\theta$** (_not_ the loss!) while using the current initial parametrization. The white point is simply $f_\\theta(\\mathbf{p})$.\n","\n","Remember: this is just $f_\\theta$ at initialization; during training, the $\\theta$ will be updated, thus $f_\\theta$ will change!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y757PaMGyG87"},"outputs":[],"source":["plot_point_over_landscape(lambda x, y: learnable_function(x, y, theta1_value, theta2_value),\n","                          point=p,\n","                          title='Function f_theta',\n","                          xaxis_title=\"x\",\n","                          yaxis_title=\"y\",\n","                          zaxis_title=\"f_theta(x, y)\")"]},{"cell_type":"markdown","metadata":{"id":"TZYk6v8z-SiF"},"source":["We can define a simple loss function $\\ell$ that quantifies the error of $f_\\theta$ at the single point $p$:\n","\n","$$\n","\\ell = (f_\\theta (\\mathbf{p}) - \\widetilde{f}(\\mathbf{p}))^2\n","$$\n","\n","Remember: we have only one $\\mathbf{p}$, because that's the only training data we are given!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8wgC0sNbzj3T"},"outputs":[],"source":["def loss(y_pred):\n","  return (y_pred  - ground_truth_fp)**2  # here the ground truth is hard coded... not a good practice :)"]},{"cell_type":"markdown","metadata":{"id":"Y_Pb-srCx7tc"},"source":["We can now visualize **how the loss changes for every possible choice of $\\theta$**.\n","\n","The white point represents the initialization that we have chosen for $\\theta$, its elevation is the energy corresponding to our chosen $\\theta$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PPeJqnyQz8Xs"},"outputs":[],"source":["plot_point_over_landscape(lambda t1, t2: loss(learnable_function(p[0], p[1], t1, t2)),\n","                          point=(theta1_value, theta2_value),\n","                          lim=5,\n","                          title='Loss landscape',\n","                          xaxis_title=\"theta1\",\n","                          yaxis_title=\"theta2\",\n","                          zaxis_title=\"E(theta1, theta2)\")"]},{"cell_type":"markdown","metadata":{"id":"v3TN0EGe0NVi"},"source":["**This** is the function we want to minimize. It's the loss (i.e., the reconstruction error at $\\mathbf{p}$), seen as a function of the model's parameters. Look at all those minima!\n","\n","Let's proceed and **find the $\\theta$ that minimize the loss**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0OX0GT9U4y_F"},"outputs":[],"source":["theta1 = torch.tensor(theta1_value, dtype=torch.float, requires_grad=True)\n","theta2 = torch.tensor(theta2_value, dtype=torch.float, requires_grad=True)\n","\n","theta1_history = [theta1.item()]\n","theta2_history = [theta2.item()]\n","\n","opt = torch.optim.Adam([theta1, theta2], lr = .025)  # we optimize theta\n","\n","for i in tqdm(range(50), desc=\"Optimization\"):\n","    out = loss(learnable_function(p[0], p[1], theta1, theta2))\n","    out.backward()\n","    opt.step()\n","    opt.zero_grad()\n","\n","    theta1_history.append(theta1.item())\n","    theta2_history.append(theta2.item())"]},{"cell_type":"markdown","metadata":{"id":"2bTfWwlP7tOE"},"source":["Let's visualize the optimization, we have two possibilities:"]},{"cell_type":"markdown","metadata":{"id":"dSr-iti0f6IP"},"source":["**1) LOSS LANDSCAPE**\n","\n","We can visualize **how the loss $\\ell$ changes** over time, while the $\\theta$ are optimized to minimize that energy.\n","\n","Here you can see how **the optimization makes a point move around in the loss landscape**.\n","\n","Remember that in this visualization the **domain are all the possible choices $\\theta \\in \\mathbb{R}^2$ of the parameters** and the value of the function is the loss of $f_{\\theta}$ computed on some fixed data: our point $\\mathbf{p}$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5SxlOE4G5Muv"},"outputs":[],"source":["# @title Optimization: loss landscape\n","\n","plot_path_over_landscape(lambda t1, t2: loss(learnable_function(p[0], p[1], t1, t2)),\n","                         x_path=theta1_history,\n","                         y_path=theta2_history,\n","                         lim=5,\n","                         title='Loss landscape',\n","                         xaxis_title=\"theta1\",\n","                         yaxis_title=\"theta2\",\n","                         zaxis_title=\"E(theta1, theta2)\")"]},{"cell_type":"markdown","metadata":{"id":"tnYCV9Vg6YgO"},"source":["**2) FUNCTION LANDSCAPE**\n","\n","We can also visualize **how $f_\\theta$ changes** over time (the plot scale is different) while the $\\theta$ are optimized.\n","\n","Here you can see how **the optimization makes the $f_\\theta$ landscape itself change**.\n","\n","Remember that:\n","- In this visualization **the domain is all the possible inputs $\\mathbf{x} \\in \\mathbb{R}^2$ of $f_\\theta$** and the value of the function is simply $f_\\theta(\\mathbf{x})$\n","- The green point is the initial estimate $f_\\theta(\\mathbf{p})$\n","- The red point is the ground-truth value $\\widetilde{f}(\\mathbf{p})=-1$"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"ch7elEWh8KAQ"},"outputs":[],"source":["# @title Optimization: function landscape\n","\n","lim = 3\n","resolution = 100\n","landscape_opacity = 1\n","height = 900\n","point = p\n","history1 = theta1_history\n","history2 = theta2_history\n","goal_point_value = ground_truth_fp\n","\n","def function_time_t(x1, x2, t):\n","  return learnable_function(x1[None, :], x2[:, None], history1[t], history2[t]).cpu().detach()\n","\n","xx = torch.linspace(-lim, lim, resolution)\n","yy = torch.linspace(-lim, lim, resolution)\n","\n","fig = go.Figure()\n","\n","fig.add_trace(\n","    go.Surface(z=function_time_t(xx, yy, 0),\n","               x=xx,\n","               y=yy,\n","               cmin=-1.5,\n","               cmid=0,\n","               cmax=.7,\n","               opacity=landscape_opacity)\n",")\n","\n","fig.update_traces(\n","    contours_z=dict(\n","        show=True, usecolormap=True, highlightcolor=\"lightgray\",\n","        project_z=False\n","    )\n",")\n","\n","fig.update_layout(\n","    title=f\"Function landscape\",\n","    height=height,\n","    scene=dict(\n","        xaxis_title=\"x\", yaxis_title=\"y\", zaxis_title=f\"{learnable_function.__name__}(x, y)\"\n","    ),\n",")\n","\n","\n","x_point, y_point = (float(p) for p in point)\n","# End point\n","fig.add_trace(\n","    go.Scatter3d(\n","        visible=True,\n","        showlegend=False,\n","        mode=\"markers\",\n","        marker=dict(size=6, color=\"red\", symbol=\"circle\"),\n","        x=[x_point],\n","        y=[y_point],\n","        z=[goal_point_value],\n","    )\n",")\n","\n","# Start point\n","fig.add_trace(\n","    go.Scatter3d(\n","        visible=True,\n","        showlegend=False,\n","        mode=\"markers\",\n","        marker=dict(size=6, color=\"green\", symbol=\"circle\"),\n","        x=[x_point],\n","        y=[y_point],\n","        z=[learnable_function(x_point, y_point, history1[0], history2[0]).cpu().detach()],\n","    )\n",")\n","\n","\n","\n","# Create frames that modify the starting path\n","frames = []\n","for j in range(len(history1)):\n","    frames.append(\n","        go.Frame(\n","            name=f\"frame{j}\",\n","            traces=[0],\n","            data=[go.Surface(z=function_time_t(xx, yy, j), x=xx, y=yy, opacity=landscape_opacity)],\n","        )\n","    )\n","\n","# Create the slider to start the animation at different timesteps\n","sliders = [\n","    dict(\n","        steps=[\n","            dict(\n","                method=\"animate\",  # Sets the Plotly method to be called when the\n","                # slider value is changed.\n","                args=[\n","                    [f\"frame{k}\"],  # Sets the arguments values to be passed to\n","                    # the Plotly method set in method on slide\n","                    dict(\n","                        mode=\"immediate\",\n","                        frame=dict(duration=50, redraw=False),\n","                        transition=dict(duration=0),\n","                    ),\n","                ],\n","                label=f\"{k}\",\n","            )\n","            for k in range(len(history1))\n","        ],\n","        currentvalue={\"prefix\": \"Iteration: \"},\n","    )\n","]\n","# If you find out how to fix the slider let me know :]\n","\n","fig[\"layout\"][\"sliders\"] = sliders\n","fig[\"layout\"][\"updatemenus\"] = [\n","    dict(\n","        type=\"buttons\",\n","        pad={\"r\": 10, \"t\": 70},\n","        showactive=False,\n","        buttons=[\n","            dict(\n","                label=\"Play\",\n","                method=\"animate\",\n","                args=[\n","                    None,\n","                    dict(\n","                        frame=dict(duration=500, redraw=True),\n","                        transition=dict(duration=0),\n","                        fromcurrent=True,\n","                        mode=\"immediate\",\n","                    ),\n","                ],\n","            ),\n","            dict(\n","                label=\"Pause\",\n","                method=\"animate\",\n","                args=[[None], dict(mode=\"immediate\")],\n","            ),\n","        ],\n","    )\n","]\n","fig.update_layout(\n","    scene = dict(\n","        zaxis = dict(range=[-1.5, 0.8])\n","        )\n",")\n","\n","fig[\"frames\"] = frames\n","\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"P41mCzbVioo-"},"source":["#### **EXERCISE**\n",">\n","> So far, we have been trying to learn $f_\\theta$ by using a dataset containing a single labeled example $(\\mathbf{p}, \\widetilde{f}(\\mathbf{p}))$.\n","> Obviously, you can use more data to better inform how $f_\\theta$ should behave.\n",">\n","> Following this observation, *optimize $f_\\theta$* after each one of the following steps:\n",">\n","> 1. Choose $k$ points $\\mathbf{p}_1, \\dots, \\mathbf{p}_k \\in \\mathbb{R}^2$ and their ground-truth values $\\widetilde{f}(\\mathbf{p}_1), \\dots, \\widetilde{f}(\\mathbf{p}_k) \\in \\mathbb{R}$. Use the mean squared error over all the $\\mathbf{p}_1, \\dots, \\mathbf{p}_k$ as the loss to minimize:\n","> $$ \\ell = \\frac{1}{k} \\sum_{i=1}^k (f_\\theta(p_i) - \\widetilde{f}(p_i))^2$$\n",">\n","> 2. Change the loss (e.g. use the $L_1$ norm instead of the $L_2$ norm on the residuals)\n",">\n","> 3. Change the parametrized function $f_\\theta$\n",">\n","> **Consider and discuss**: which elements influence the shape of the loss landscape?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EBaT7iolmh9f"},"outputs":[],"source":["# ✏️ your solution here"]}],"metadata":{"colab":{"collapsed_sections":["iXd3HJRDfLEO","UvrnMPqEi8tH","s00hN6W4k2HR","qb6JXFrQftIE","_xpMqBAJfzyc","9b-qUjGSzK1l","_JcRld0z43cu","U2eKSdGZCqXc","h71mh066FQ0K","5LaIS0vU9QBj","H0bauc84HDZI","N5yT0fptmAbI","CVgjkHqEsfpz","xpfC6MtSzj1a","8pbUkeGInqo6","QtGwWrVozyst","bQPNQ7O6tgxB","bLgvF66DrOqH","2SfcOlmR3K4l","DgTAQ-1v6DSb","O_UW943f3K46","P41mCzbVioo-"],"toc_visible":true,"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}