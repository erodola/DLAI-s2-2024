{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"collapsed_sections":["ezcEIBPFSlFa","HKMXdwUdRN4U"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"AhTm-wTJNJEJ"},"source":["# Deep Learning & Applied AI\n","\n","# Tutorial 2: Tensor operations\n","\n","In this tutorial, we will cover:\n","\n","- Tensor operations: broadcasting, (not)-elementwise operations, tensor contraction, einsum\n","\n","Our info:\n","\n","- Based on original material by Dr. Antonio Norelli (norelli@di.uniroma1.it)\n","\n","Course:\n","\n","- Website and notebooks will be available at https://erodola.github.io/DLAI-s2-2024/\n","\n"]},{"cell_type":"markdown","metadata":{"id":"4t5Enszg17Yr"},"source":["## Introduction\n","\n","In this tutorial we will continue to learn basic tensor usage, we will cover  broadcasting, fundamental linear algebra operations, and finally `einsum`, a single operation implementing the Einstein notation to rule them all!\n","\n","All these tensor operations will come in handy to build our deep neural networks.\n","Yet, the high level API offered by PyTorch to perform GPU-acccelerated linear algebra operations may turn useful in many other fields, from microbiology to fluid dynamics.\n","\n","The GPU computing paradigm offers several benefits over single-core machines or traditional supercomputers equipped with many single-core nodes.\n","Deep learning frameworks such as the one we are studying are a very good compromise between simplicity and expressivenes to unleash the power of GPU-computing.\n","\n","To get even more control you can tackle directly the CUDA language, but we won't go there with this course!"]},{"cell_type":"markdown","metadata":{"id":"dHLO4Z-T_yxB"},"source":["## PyTorch\n","\n","**Reminder:** Familiarize with the [PyTorch Documentation](https://pytorch.org/docs/stable/) as it will greatly assist you.\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"pRePt-K1_yw9"},"source":["import torch\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p0B2Y47YJY97"},"source":["# Utility print function\n","\n","from typing import Union\n","\n","def print_arr(*arr: Union[torch.Tensor, np.ndarray], prefix: str = \"\") -> None:\n","    \"\"\"Pretty print tensors, together with their shape and type\n","\n","    :param arr: one or more tensors\n","    :param prefix: prefix to use when printing the tensors\n","    \"\"\"\n","    print(\n","        \"\\n\\n\".join(\n","            f\"{prefix}{str(x)} <shape: {x.shape}> <dtype: {x.dtype}>\" for x in arr\n","        )\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bie5eT1Md_FW"},"source":["####Set torch and numpy random seeds for reproducibility\n","\n","As we will see, several operations in deep learning (e.g. training a network) rely on randomness in order to work effectively. This means that we will get different results each time we run a test, which can make design and debugging difficult.\n","\n","To this end, we usually **set a fixed seed** for the pseudo-random number generator, so that we are sure to always see the \"same randomness\" that makes our tests reproducible.\n","\n","> Once your model works, remember to test multiple times _without_ a fixed seed! The results you got at design time may be due to overfitting the seed (e.g. you have chosen hyperparameters that happen to work particularly well with a given seed.), or just out of luck.\n","\n","If you are going to use a gpu, two further options must be set."]},{"cell_type":"code","metadata":{"id":"2tGN_bJOcfd3"},"source":["import random\n","\n","np.random.seed(42)\n","random.seed(0)\n","\n","torch.manual_seed(0)\n","torch.cuda.manual_seed_all(0)\n","torch.backends.cudnn.deterministic = True  # Note that this Deterministic mode can have a performance impact\n","torch.backends.cudnn.benchmark = False\n","\n","# We will see frameworks that aid the reproducibility of your code,\n","# e.g. PyTorch Lightning exposes a `seed_everything` function by default:\n","# https://github.com/PyTorchLightning/pytorch-lightning/blob/e1f5eacab98670bc1de72c88657404a15aadd527/pytorch_lightning/utilities/seed.py#L29"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SUl8vYRv_yuG"},"source":["### **Tensor operations**\n","\n"]},{"cell_type":"code","metadata":{"id":"bFFU6Xw7_yuA"},"source":["t = torch.rand(3,3)\n","t"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5pMboSXXogDd"},"source":["Functions that operate on tensors are often accessible in different ways:\n","\n","- From the **`torch` module**...:"]},{"cell_type":"code","metadata":{"id":"Cpff92U3obK5"},"source":["torch.add(t, t)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zD99wCT8_yt0"},"source":["- ...or by tensors **methods**:"]},{"cell_type":"code","metadata":{"id":"_zkKPFHo_ytw"},"source":["t.add(t)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3TKgi2HL_yt_"},"source":["- ...or even through **overloaded** operators:\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"HydKd9OK_yt7"},"source":["t + t"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["None of the above operates in-place:"],"metadata":{"id":"5JyOSdbKfnkl"}},{"cell_type":"code","metadata":{"id":"FcRwwHVfoVOD"},"source":["# t is unchanged\n","t"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PuJlpLP-gWMj"},"source":["These functions are all equivalent, they are *aliases* of the same method.\n","Personal preference, code consistency, and readability should guide your decision of which one to use.\n","\n","> e.g. `torch.add(...)` may be too verbose, but in some cases it may be preferable since it makes explicit to the code-reader that you are dealing with tensors. Nevertheless, if you are using [types](https://docs.python.org/3/library/typing.html) -- and you should be using types -- it will be rarely necessary."]},{"cell_type":"markdown","metadata":{"id":"_Amiof4a_yt6"},"source":["\n","Most operation in PyTorch are **not in-place**. It means that the resulting tensor is a *new* tensor, and it does not share the underlying data with other tensors. Changes to the new tensor are not reflected to other tensors.\n","We will see in future tutorials why this is important, for now a TLDR is: **in-place operations may break the auto-differentiation mechanism**.\n","\n","\n","In-place operations are still available in PyTorch, and in some cases (e.g. when you don't need autodiff) they can be useful; they are more efficient, since they never require to perform deep copies of the data.\n","They are normally recognized by a trailing `_`:"]},{"cell_type":"code","metadata":{"id":"8NB70TkLiApB"},"source":["t"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7FKDL8ZG_yt2"},"source":["t.add_(t)  # notice the trailing _"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YxG3NsBOiFN3"},"source":["t  # t itself changed!"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r2dWLk0ji-vD"},"source":["Another common in-place operation is the assignment:"]},{"cell_type":"code","metadata":{"id":"IqYinZnGjB-n"},"source":["t[0] = 42\n","t"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aQ9ChdjH_ytv"},"source":["#### **Basic operations and broadcasting**\n","\n","Basic mathematical operations $(+, -, *, /, **)$ are applied **element-wise**: for example, if `x` and `y` are two tensors, the product `x*y` is a tensor with the same size, and its values are the element-wise products of the two tensors. In mathematics, this is also called a Hadamard product.\n","\n","**Broadcasting** is another powerful mechanism that allows PyTorch to perform operations on tensors of different shapes. The most basic example is summing a scalar (a rank-0 tensor) to a matrix (a rank-2 tensor)."]},{"cell_type":"code","metadata":{"id":"doNfhKA5_ytq"},"source":["x = torch.tensor([[1, 2], [3, 4]], dtype=torch.float64)\n","y = torch.tensor([[5, 6], [7, 8]], dtype=torch.float64)\n","\n","print(x + y)  # element-wise sum\n","print(x + 4.2)  # broadcasting"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GlZG4i_D_ytj"},"source":["# other examples\n","print(x * y - 5)\n","print((x - y) / y)  # element-wise division!"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2rNTtIs2NMKt"},"source":["Broadcasting is quite powerful! When you perform an operation between two tensors with different shape, PyTorch automatically \"broadcasts\" the smaller tensor across the larger tensor so that they have compatible shapes.\n","\n","In the example below, the sequence `v` is replicated (_without actually copying data!_) along the missing dimension so that it fits the shape of matrix `m`:"]},{"cell_type":"code","metadata":{"id":"4XzPdOKXNLV-"},"source":["m = torch.arange(12).reshape(4, 3)\n","v = torch.tensor([100, 0, 200])\n","n = m + v\n","print_arr(m, v, n)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In this other example `m` and `u` are both rank-2, but the smaller one (`u`) is expanded along the dimension where it has size 1 to fit `m`:"],"metadata":{"id":"D4IlFl_ZjybT"}},{"cell_type":"code","metadata":{"id":"CYREKQAuQNYy"},"source":["m = torch.arange(12).reshape(4, 3)\n","u = torch.tensor([0, 10, 0, 20]).reshape(4,1)\n","n = m + u\n","print_arr(m, u, n)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In the following example, both tensors are expanded along their size-1 dimensions, so that the sum makes sense:"],"metadata":{"id":"XZoseFdYkTpG"}},{"cell_type":"code","metadata":{"id":"ReNq-RtKg1Dy"},"source":["w = u + v\n","print_arr(u, v, w)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sYNysSHoQ6dX"},"source":["Mastering broadcasting is hard!\n","\n","However, it is very convenient as it allows writing **vectorized** code, i.e., code that avoids explicit python loops which can not be efficiently parallelized.\n","\n","Technically, broadcasting takes advantage of the underlying C implementation of PyTorch and Numpy (on CPU) or CUDA implementation of Pytorch (on GPU). Here's a take-home illustration for your convenience:\n","\n","![broadcasting](https://jakevdp.github.io/PythonDataScienceHandbook/figures/02.05-broadcasting.png)"]},{"cell_type":"markdown","metadata":{"id":"PqyMVYPL_yoC"},"source":["##### **EXERCISE**\n",">\n","> Given two vectors $x \\in \\mathbb{R}^n$ and $y \\in \\mathbb{R}^m$, compute the differences between all possible pairs of their elements, and organize these differences in a matrix $Z \\in \\mathbb{R}^{n \\times m}$:\n","> $$ z_{ij} = x_i - y_j $$"]},{"cell_type":"code","metadata":{"id":"-WqFqMkksOBg"},"source":["x = torch.tensor([1, 2, 3])\n","y = torch.tensor([4, 5])\n","\n","# ✏️ your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gtF2--mB_yn1","cellView":"form"},"source":["# @title 👀 Solution\n","\n","\n","out = x.unsqueeze(1) - y\n","\n","# equivalent to:\n","# x.reshape([-1, 1]) - y\n","\n","# equivalent to:\n","# x[:, None] - y\n","\n","# equivalent to:\n","# x[:, None] - y[None, :]\n","\n","print_arr(x, y, out)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ezcEIBPFSlFa"},"source":["#### 📖 **Broadcasting, let's take a peek under the hood**\n","\n","To recap: if a PyTorch operation supports broadcast, then **its tensor arguments can be implicitly expanded to be of equal sizes** (without making copies of the data)."]},{"cell_type":"markdown","metadata":{"id":"CfTF3SiYSlFg"},"source":["###### **Broadcastable tensors**\n","\n","Two tensors are \"broadcastable\" if:\n","- Each tensor has at least one dimension\n","- When iterating over the dimension sizes, starting at the trailing dimension, the dimension **sizes** must either **be equal**, **one of them is 1**, or **one of them does not exist**.\n"]},{"cell_type":"markdown","metadata":{"id":"Mdgd4qM5SlFh"},"source":["###### **Broadcasting rules**\n","\n","Broadcasting two tensors together follows these rules:\n","\n","1. If the input tensors have different ranks, **singleton dimensions are prepended to the shape** of the smaller one until it has the same rank as the other\n","2. The size in each dimension of the **output shape** is the maximum size in that dimension between the two tensors\n","3. An input can be used in the computation if its size in a particular **dimension either matches** the output size in that dimension, **or is a singleton dimension**\n","4. If an input has a dimension size of 1 in its shape, the **first data entry in that dimension will be used for all calculations** along that dimension."]},{"cell_type":"markdown","metadata":{"id":"dcj42Be5SlFi"},"source":["**Example**:\n","\n","- `m` has shape `[4, 3]`\n","- `v` has shape `[3,]`.\n"]},{"cell_type":"code","metadata":{"id":"lXQWIJtoSlFj"},"source":["print_arr(m, v)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n = m + v\n","print_arr(n)"],"metadata":{"id":"MEdjjDButCVa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mZLeIamSSlFn"},"source":["\n","Following the Broadcasting logic, this is what happened:\n","\n","- `v` has less dims than `m` so a dimension of `1` is **prepended** $\\to$ `v` is now `[1, 3]`.\n","- Output shape will be `[max(1, 4), max(3, 3)] = [4, 3]`.\n","- `dim 1` of `v` matches exactly `3`; `dim 0` is `1`, so we can use the first data entry in that dimension (i.e. the whole `row 0` of `v`) each time any row is accessed. This is effectively like converting `v` from `[1, 3]` to `[4, 3]` by stacking the repeated row four times."]},{"cell_type":"markdown","metadata":{"id":"xeoux-PvSlFp"},"source":["\n","For more on broadcasting, see the [documentation](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html).\n","\n","Functions that support broadcasting are known as universal functions (i.e. ufuncs). For Numpy you can find the list of all universal functions in the [documentation](https://docs.scipy.org/doc/numpy/reference/ufuncs.html#available-ufuncs)."]},{"cell_type":"markdown","metadata":{"id":"L_L_GYRgsnLo"},"source":["#### **EXERCISE**\n",">\n","> Given a tensor $Y \\in \\mathbb{R}^{n \\times m}$ and an index pair $(a,b)$, for each element of $Y$ compute its $L_p$ distance to $(a,b)$, and store the resulting distance value in the corresponding cell of $Y$.\n",">\n","> In brief, compute:\n","> $$ y_{ij} = d_{L_p}\\left( (i,j), (a,b) \\right) \\text{ for all }  i,j$$\n",">\n","> and visualize the resulting $Y$.\n",">\n","> Try different values of $p>0$ to see what happens.\n",">\n","> ---\n",">\n","> The [$L_p$ distance](https://en.wikipedia.org/wiki/Lp_space#The_p-norm_in_finite_dimensions) between two points $x$ and $y$ can be computed as: $d_{L_p}(x, y)=\\left( \\sum_{i=1}^n|x_i - y_i|^p\\right)^{1/p}$\n",">\n","> Example: The $L_1$ distance between $(i,j) = (3, 5)$ and $(a,b) = (14, 20)$ is:\n","> $$ y_{3,5} = d_{L_1}( (3, 5), (14, 20) ) = |3 - 14| + |5 - 20| $$"]},{"cell_type":"code","metadata":{"id":"mdW4Xf964XQ1","cellView":"form"},"source":["# @title Utility function, you can execute and safely ignore this cell\n","\n","import plotly.express as px\n","\n","def plot_row_images(images: Union[torch.Tensor, np.ndarray]) -> None:\n","  \"\"\" Plots the images in a subplot with multiple rows.\n","\n","  Handles correctly grayscale images.\n","\n","  :param images: tensor with shape [number of images, width, height, <colors>]\n","  \"\"\"\n","  from plotly.subplots import make_subplots\n","  import plotly.graph_objects as go\n","  fig = make_subplots(rows=1, cols=images.shape[0] ,\n","                      specs=[[{}] * images.shape[0]])\n","\n","  # Convert grayscale image to something that go.Image likes\n","  if images.dim() == 3:\n","    images = torch.stack((images, images, images), dim= -1)\n","  elif (images.dim() == 4 and images.shape[-1] == 1):\n","    images = torch.cat((images, images, images), dim= -1)\n","\n","  assert images.shape[-1] == 3 or images.shape[-1] == 4\n","\n","  for i in range(images.shape[0]):\n","    i_image = np.asarray(images[i, ...])\n","\n","    fig.add_trace(\n","        go.Image(z = i_image, zmin=[0, 0, 0, 0], zmax=[1, 1, 1, 1]),\n","        row=1, col=i + 1\n","    )\n","\n","  fig.show()\n","\n","\n","# When using plotly pay attention that it often does not like PyTorch Tensors\n","# ...and it does not give any error, just a empty plot."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ApPt8XdAuK7R"},"source":["x = torch.zeros(300, 300)\n","a = 150\n","b = 150\n","\n","x[a, b] = 1  # this will be overwritten by your distance-calculating code\n","plot_row_images(x[None, :])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mFwiTbVV7iho"},"source":["# ✏️ your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MUDYSUxLuoAK","cellView":"form"},"source":["# @title 👀 Solution\n","\n","\n","rows = torch.arange(x.shape[0])\n","cols = torch.arange(x.shape[1])\n","\n","# Manual computation of L1\n","y = (torch.abs(rows - a)[:, None] + torch.abs(cols - b)[None, :])\n","px.imshow(y).show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PYF38G6dwAbT","cellView":"form"},"source":["# @title 👀 Solution\n","\n","\n","# Parametric computation of Lp\n","p = 8\n","y = ((torch.abs(rows - a ) ** p )[:, None] +\n","     (torch.abs(cols - b) ** p)[None, :]) ** (1/p)\n","px.imshow(y).show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0O530uju9a0h"},"source":["Try Solution 2 with `p=10`. What happens, and why?"]},{"cell_type":"code","metadata":{"id":"NYZfn5gJ5kOM","cellView":"form"},"source":["# @title 👀 Solution\n","\n","\n","# This works even with p=10. Why?\n","p = 10\n","y = ((torch.abs(rows.double() - a ) ** p )[:, None] +\n","     (torch.abs(cols.double() - b) ** p)[None, :]) ** (1/p)\n","px.imshow(y).show()\n","\n","# -> Write your own explanation here\n","p = 10\n","print(torch.tensor(10, dtype=torch.int) ** p)\n","print(torch.tensor(10, dtype=torch.double) ** p)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vpE0yZGF_ytT"},"source":["#### **Non-elementwise operations**\n","\n","\n","PyTorch and NumPy provide many useful functions to perform computations on tensors:"]},{"cell_type":"code","metadata":{"id":"EI33i1Df_ytN"},"source":["x = torch.tensor([[1, 2, 3], [3, 4, 5]], dtype=torch.float32)\n","print_arr(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6x4rhtfI_ytI"},"source":["# Sum up all the elements\n","print_arr(torch.sum(x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OvndASPe_ytD"},"source":["# Compute the mean of each column\n","print_arr(torch.mean(x, dim=0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HUwZxvZP_ysy"},"source":["> **REMEMBER!**\n",">\n","> In order to avoid confusion with the `dim` parameter, you can think of it as an **index over the list returned by `tensor.shape`**. The operation is performed by iterating over that dimension.\n",">\n","> Example above: since our tensor `x` has shape `[2, 3]`, the dimension `dim=0` operates along the `2`.\n",">\n","> Visually (here array means _tensor_):\n",">\n","><img src=\"https://qph.fs.quoracdn.net/main-qimg-30be20ab9458b5865b526d287b4fef9a\" width=\"500\" >"]},{"cell_type":"code","source":["print_arr(x)"],"metadata":{"id":"puZDDaDfgDK8"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4K-4z5pL_ys-"},"source":["# Compute the product of each row\n","print_arr(torch.prod(x, dim=1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MRtgzF33_ys4"},"source":["# Max along the rows (i.e. max value in each column)\n","values, indices = torch.max(x, dim=0)\n","print_arr(values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hd0zbRp0_ys0"},"source":["# Max along the columns (i.e. max value in each row)\n","values, indices = torch.max(x, dim=1)\n","print_arr(values)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D1xEs8jkkk4f"},"source":["##### 📖 **Dim parameter, let's take a peek under the hood**\n"]},{"cell_type":"markdown","metadata":{"id":"gwORY20xmzq8"},"source":["Let's see what the `dim` parameter exactly does:"]},{"cell_type":"code","metadata":{"id":"DoDvtWHq_ysu"},"source":["dim = 2\n","\n","a = torch.arange(2*3*4).reshape(2, 3, 4)\n","out = a.sum(dim=dim)\n","out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9-KbxoTK_ysq"},"source":["# It is summing over the `dim` dimension, i.e.:\n","a.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mZcG-q5R_ysm"},"source":["# The `dim` dimension has 4 elements\n","a.shape[dim]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zqT4jSkW_ysi"},"source":["# The dimension dim collapses, the output tensor will have shape:\n","new_shape = a.shape[:dim] + a.shape[dim + 1:]\n","new_shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GHakpxbl_ysd"},"source":["# Explicitly compute the sum over dim\n","out = torch.zeros(new_shape)\n","\n","# iterate over all the rows\n","for r in range(a.shape[0]):\n","  # iterate over all the columns in the r-th row\n","  for c in range(a.shape[1]):\n","\n","    for i in range(a.shape[dim]): # <- sum over 'dim'\n","\n","      out[r, c] += a[r, c, i]\n","\n","out\n","\n","# **DO NOT** use for loops in your code"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LQA3ngqoHsEt"},"source":["###### **EXERCISE**\n",">\n","> Given a matrix $X \\in R^{k \\times k}$:\n","> - Compute the mean of the values along its diagonal.\n",">\n","> Perform this computation in at least two different ways, then check that the results are the same."]},{"cell_type":"code","metadata":{"id":"evQYg9-GH-Td"},"source":["x = torch.rand(4, 4)\n","print_arr(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3x8-6wyGcB_R"},"source":["# ✏️ your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fOEhv8X0ILC2","cellView":"form"},"source":["# @title 👀 Solution\n","\n","\n","a = torch.mean(x[torch.arange(x.shape[0]), torch.arange(x.shape[1])])\n","b = torch.sum(torch.eye(x.shape[0]) * x) / x.shape[0]\n","c = torch.trace(x) / x.shape[0]\n","d = torch.mean(torch.diag(x))\n","\n","print(torch.equal(a, b) and torch.equal(a, c) and torch.equal(a, d))\n","print_arr(a)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YePwf4ok_ysb"},"source":["##### **EXERCISE**\n",">\n","> Given a binary non-symmetric matrix $X \\in \\{0, 1\\}^{n\\times n}$, build the symmetric matrix $Y \\in \\{0, 1\\}^{n \\times n}$ defined as:\n","> $$\n","y_{ij} =\n","\\begin{cases}\n","1 & \\text{if } x_{ij} = 1 \\\\\n","1 & \\text{if } x_{ji} = 1 \\\\\n","0 & \\text{otherwise}\n","\\end{cases}\n","$$\n",">\n","> *Hint*: search for `clamp` in the [docs](https://pytorch.org/docs/stable/index.html)"]},{"cell_type":"code","metadata":{"id":"2Dv-OmnV_ysU"},"source":["x = torch.randint(0, 2, (5, 5))  # Non-symmetric matrix\n","x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j6HT6OSElDic"},"source":["# ✏️ your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4tM6Yd14JrAB","cellView":"form"},"source":["# @title 👀 Solution\n","\n","\n","(x + x.transpose(1, 0)).clamp(max=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cVC3YH8H_ysT"},"source":["#### **Tensor contractions**"]},{"cell_type":"markdown","metadata":{"id":"QewYLJq-_yr5"},"source":["##### **Matrix multiplication**\n","\n","Given $X \\in R^{n \\times d}$ and $Y \\in R^{d \\times v}$, their matrix multiplication $Z \\in R^{n \\times v}$ is defined as:\n","\n","$$ \\sum_{k=0}^{d} x_{ik} y_{kj} = z_{ij} $$\n"]},{"cell_type":"code","metadata":{"id":"qu16frkd_yru"},"source":["x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n","y = torch.tensor([[1, 2], [2, 1]])\n","print_arr(x, y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# as we will see, matmul's functionality is not limited to matrix-matrix multiplication\n","torch.matmul(x, y)"],"metadata":{"id":"ag_EbhhOH1Xp"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PbVbXIzz_yrl"},"source":["x @ y  # Operator overload for matmul"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_FKQsMIG_yrh"},"source":["torch.mm(x, y)  # PyTorch function, only works for rank-2 tensors (matrices) https://pytorch.org/docs/stable/generated/torch.mm.html"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qfmI4xltpJlO"},"source":["x.mm(y)  # Tensor method"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tTqIXFNU_yrZ"},"source":["torch.einsum('ik, kj -> ij', (x, y))  # Einsum notation!\n","\n","# It summed up dimension labeled with the index `k`"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V-KPmcQg_ysS"},"source":["##### **Dot product**\n","Also known as scalar product or inner product.\n","Given $x \\in \\mathbb{R}^k$ and $y \\in \\mathbb{R}^k$, the dot product $z \\in \\mathbb{R}$ is defined as:\n","\n","$$ \\sum_{i=0}^{k} x_i y_i = z $$"]},{"cell_type":"code","metadata":{"id":"6DxmdUoC_ysM"},"source":["x = torch.tensor([1, 2, 3])\n","y = torch.tensor([4, 5, 6])\n","print_arr(x, y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ixf_iXF3KbOv"},"source":["# We want to perform:\n","(1 * 4) + (2 * 5) + (3 * 6)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c0jRMizc_ysG"},"source":["torch.dot(x, y)  # PyTorch function"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6xzISunbpeUi"},"source":["x.dot(y) # Tensor method"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GrW2utM9_ysA"},"source":["x @ y  # PyTorch operator again overloading matmul"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xWV3hiAU_yr7"},"source":["torch.einsum('i, i ->', (x, y))  # Einstein notation!\n","\n","# Read it as:\n","# - iterate with i along x\n","# - iterate with i along y\n","# - compute the product at each iteration\n","# - sum the products and return a scalar (-> means return a scalar)\n","\n","# More in general, Einstein notation:\n","# Multiply point-wise repeated indices in the input\n","# Sum up along the indices that `do not` appear in the output\n","\n","# More on this below!"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3a9Yl0IC_yrW"},"source":["##### **Batch matrix multiplication**\n","\n","Often we want to perform more operations together. Why?\n","- Reduce the **overhead of uploading** each tensor to/from the GPU memory\n","- **Better parallelization** of the computation\n","\n","Given two 3D tensors, each one containing ``b`` matrices,\n","$X \\in \\mathbb{R}^{b \\times n \\times m}$\n","and  \n","$Y \\in \\mathbb{R}^{b \\times m \\times p}$,\n","\n","We want to multiply together each $i$-th pair of matrices, obtaining a tensor $Z \\in \\mathbb{R}^{b \\times n \\times p}$ defined as:\n","\n","$$ z_{bij} = \\sum_{k=0}^m x_{bik} y_{bkj} $$"]},{"cell_type":"code","metadata":{"id":"wwUMo2Br_yrQ"},"source":["# here b = 2 matrices\n","x = torch.tensor([[[1, 2], [3, 4], [5, 6]], [[1, 2], [3, 4], [5, 6]]])  # 3x2 matrices\n","y = torch.tensor([[[1, 2], [2, 1]], [[1, 2], [2, 1]]])  # 2x2 matrices\n","print_arr(x, y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDW_9XKJ_yrG"},"source":["torch.bmm(x, y)  # **not** torch.mm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zf7GaNmw_yrM"},"source":["# Operator overload! again, matmul is actually doing the job\n","x @ y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wjjRPx-n_yrC"},"source":["torch.einsum('bik, bkj -> bij', (x, y)) # Einstein notation!"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S-aYQyHz_yrA"},"source":["##### 📖 **Broadcast matrix multiplication**\n","\n","Given a matrix $Y \\in \\mathbb{R}^{m \\times p}$ and $b$ matrices of size $n \\times m$ organized in a 3D tensor $X \\in \\mathbb{R}^{b \\times n \\times m}$, we want to multiply together each matrix $X_{i,:,:}$ with $Y$, obtaining a tensor $Z \\in R^{b \\times n \\times p}$ defined as:\n","\n","$$ z_{bij} = \\sum_{k=0}^m x_{bik} y_{kj} $$\n"]},{"cell_type":"code","metadata":{"id":"awE5anPp_yq7"},"source":["x = torch.tensor([[[1, 2], [3, 4], [5, 6]], [[1, 2], [3, 4], [5, 6]]])\n","y = torch.tensor([[1, 2], [2, 1]])\n","print_arr(x, y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fvZyCiYN_yqz"},"source":["torch.matmul(x, y)  # always uses the last two dimensions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L7fxtm64_yq3"},"source":["x @ y   # still using the last two dimensions since @ overloads matmul"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iod-0Z04_yqx"},"source":["##### **EXERCISE**\n",">\n","> Use the einsum notation to compute the equivalent broadcast matrix multiplication!"]},{"cell_type":"markdown","metadata":{"id":"LsgxdJnP_yqv"},"source":["### **Einsum notation**\n","\n","Einstein notation is a way to express complex operations on tensors.\n","\n","- It is **concise but expressive enough** to perform almost every operation you will need in building your neural networks, allowing you to think of the only thing that matters... **dimensions!**\n","- You will **not need to check your dimensions** after an einsum operation, since the dimensions themselves are *defining* the tensor operation.\n","- You will **not need to shape-comment** your tensors. Those comments do not work: they are bound to get outdated.\n","-  You will not need to explicitly code **intermediate operations** such as reshaping, transposing and intermediate tensors.\n","- It is **not library-specific**, being avaiable in ``numpy``, ``pytorch``, ``tensorflow`` and ``jax`` with the same signature. So you do not need to remember the functions signature in all the frameworks.\n","- It can sometimes be compiled to high-performing code (e.g. [Tensor Comprehensions](https://pytorch.org/blog/tensor-comprehensions/))\n","\n","Check [this blog post by Olexa Bilaniuk](https://obilaniu6266h16.wordpress.com/2016/02/04/einstein-summation-in-numpy/) to take a peek under the hood of einsum and [this one by Tim Rocktäschel](https://rockt.github.io/2018/04/30/einsum) for several examples.\n","\n","Its formal behavior is well described in the [Numpy documentation](https://docs.scipy.org/doc/numpy/reference/generated/numpy.einsum.html).\n","However, it is very intuitive and better explained through examples.\n","\n","![alt text](https://obilaniu6266h16.files.wordpress.com/2016/02/einsum-fmtstring.png?w=676)\n","\n","> *Historical note (taken from O.Bilaniuk's post)*\n",">\n","> Einstein had no part in the development of this notation. He merely popularized it, by expressing his entire theory of General Relativity in it. In a letter to [Tullio Levi-Civita](https://en.wikipedia.org/wiki/Tullio_Levi-Civita), co-developer alongside [Gregorio Ricci-Curbastro](https://en.wikipedia.org/wiki/Gregorio_Ricci-Curbastro) of Ricci calculus (of which this summation notation was only a part), Einstein wrote:\n",">\n","> \" *I admire the elegance of your method of computation; it must be nice to ride through these fields upon the horse of true mathematics while the like of us have to make our way laboriously on foot.* \""]},{"cell_type":"code","metadata":{"id":"UdyM0vLB_yqq"},"source":["a = torch.arange(6).reshape(2, 3)  # will use this in the examples below"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ow4puwv4_yqp"},"source":["###### **Matrix transpose**\n","\n","$$ B_{ji} = A_{ij} $$"]},{"cell_type":"code","metadata":{"id":"LmE5nSrt_yqk"},"source":["# The characters are indices along each dimension\n","b = torch.einsum('ij -> ji', a)\n","print_arr(a, b)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Z8j-iVH_yqi"},"source":["###### **Sum**\n","\n","$$ b = \\sum_i \\sum_j A_{ij} := A_{ij} $$\n"]},{"cell_type":"code","metadata":{"id":"HFjp7cOb_yqd"},"source":["# Indices that do not appear in the output tensor are summed up\n","b = torch.einsum('ij -> ', a)\n","print_arr(a, b)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hks-z_NN_yqb"},"source":["###### **Column sum**\n","\n","$$ b_j = \\sum_i A_{ij} := A_{ij} $$"]},{"cell_type":"code","metadata":{"id":"MXbTLNtL_yqX"},"source":["# Indices that do not appear in the output tensor are summed up,\n","# ...even if some other index appears\n","b = torch.einsum('ij -> j', a)\n","print_arr(a, b)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yDSB2iy0Mjf3"},"source":["###### **EXERCISE**\n",">\n","> Given a binary tensor $X \\in \\{0, 1\\}^{n \\times m}$ return a tensor $y \\in \\mathbb{R}^{n}$ that has in the $i$-th position the **number of ones** in the $i$-th row of $X$.\n",">\n",">Give a solution using `einsum`, and a solution using standard manipulation."]},{"cell_type":"code","source":["x = (torch.rand(100, 200) > 0.5).int()"],"metadata":{"id":"Mj-Vw04DMAyn"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5sewLwDHNdQq"},"source":["# Display a binary matrix with plotly\n","\n","fig = px.imshow(x)\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C-YO6eOmrUkK"},"source":["# ✏️ your code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iVQEYEThQn-I","cellView":"form"},"source":["# @title 👀 Solution\n","\n","\n","# Count the number of ones in each row\n","row_ones = torch.einsum('ij -> i', x)\n","\n","row_ones2 = torch.sum(x, dim=-1)  # recall that -1 refers to the last dimension\n","\n","torch.equal(row_ones, row_ones2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bUlzmmfTQ_p8"},"source":["px.imshow(row_ones[:, None]).show()\n","print(f'Sum up the row counts: {row_ones.sum()}\\nSum directly all the ones in the matrix: {x.sum()}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JA5cWXv3_yqN"},"source":["###### **Matrix-vector multiplication**\n","\n","$$ c_i = \\sum_k A_{ik}b_k := A_{ik}b_k $$"]},{"cell_type":"code","metadata":{"id":"zYF4uNUC_yqJ"},"source":["# Repeated indices in different input tensors indicate pointwise multiplication\n","a = torch.arange(6).reshape(2, 3)\n","b = torch.arange(3)\n","c = torch.einsum('ik, k -> i', [a, b])  # Multiply on k, then sum up on k\n","print_arr(a, b, c)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qDsla37O_yqH"},"source":["###### **Matrix-matrix multiplication**\n","\n","$$ C_{ij} = \\sum_k A_{ik}B_{kj} := A_{ik}B_{kj} $$"]},{"cell_type":"markdown","metadata":{"id":"G8khafOAKElM"},"source":["📖 Understanding einsum, what happens inside?\n","\n","![alt text](https://obilaniu6266h16.files.wordpress.com/2016/02/einsum-matrixmul.png?w=676)"]},{"cell_type":"code","metadata":{"id":"7mcYlmu5_yqD"},"source":["a = torch.arange(6).reshape(2, 3)\n","b = torch.arange(15).reshape(3, 5)\n","c = torch.einsum('ik, kj -> ij', [a, b])\n","print_arr(a, b, c)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wVAJP6Ma_yqC"},"source":["###### **Dot product multiplication**\n","\n","$$ c = \\sum_i a_i b_i := a_i b_i $$"]},{"cell_type":"code","metadata":{"id":"2x-XwGOy_yp6"},"source":["a = torch.arange(3)\n","b = torch.arange(3,6)\n","c = torch.einsum('i,i->', (a, b))\n","print_arr(a, b, c)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xhLZ4Gl__yp4"},"source":["###### **Point-wise multiplication**\n","Also known as Hadamard product:\n","\n","$$ C_{ij} = A_{ij} B_{ij} $$"]},{"cell_type":"code","metadata":{"id":"QTUH61Ft_yp0"},"source":["a = torch.arange(6).reshape(2, 3)\n","b = torch.arange(6,12).reshape(2, 3)\n","c = torch.einsum('ij, ij -> ij', (a, b))\n","print_arr(a, b, c)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dZoiSCsn_ypz"},"source":["###### **Outer product**\n","Given two column vectors of length $m$ and $n$ respectively,\n","\\begin{align*}\n","\\mathbf{a}=\\left[\\begin{array}{c}\n","a_{1} &\n","a_{2} &\n","\\dots &\n","a_{m}\n","\\end{array}\\right]^\\top, \\quad \\mathbf{b}=\\left[\\begin{array}{c}\n","b_{1} &\n","b_{2} &\n","\\dots &\n","b_{n}\n","\\end{array}\\right]^\\top\n","\\end{align*}\n","their outer product, denoted $\\mathbf{a} \\otimes \\mathbf{b}$, is defined as the $m \\times n$ matrix $\\mathbf{C}$ obtained by multiplying each element of $\\mathbf{a}$ by each element of $\\mathbf{b}$:\n","\\begin{align*}\n","\\mathbf{a} \\otimes \\mathbf{b}=\\mathbf{C}=\\left[\\begin{array}{cccc}\n","a_{1} b_{1} & a_{1} b_{2} & \\ldots & a_{1} b_{n} \\\\\n","a_{2} b_{1} & a_{2} b_{2} & \\ldots & a_{2} b_{n} \\\\\n","\\vdots & \\vdots & \\ddots & \\vdots \\\\\n","a_{m} b_{1} & a_{m} b_{2} & \\ldots & a_{m} b_{n}\n","\\end{array}\\right]\n","\\end{align*}\n","Or, in index notation,\n","$$ C_{ij} = a_i b_j $$"]},{"cell_type":"code","metadata":{"id":"k71BkJbf_ypu"},"source":["a = torch.arange(3)\n","b = torch.arange(3,7)\n","c = torch.einsum('i, j -> ij', (a, b))\n","print_arr(a, b, c)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1MQYFeM2_ypo"},"source":["# Using the standard PyTorch API\n","torch.outer(a, b)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Using broadcasting black magic\n","a[:, None] * b[None, :]"],"metadata":{"id":"vuElOQ9YkjiW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HXQHwUet_yph"},"source":["###### 📖 **Batch matrix multiplication**\n","\n","$$ c_{bij} = \\sum_k a_{bik} b_{bkj} $$"]},{"cell_type":"code","metadata":{"id":"6vpbY37H_ypb"},"source":["a = torch.randn(2,2,5)\n","b = torch.randn(2,5,3)\n","c = torch.einsum('bik,bkj->bij', [a, b])\n","print_arr(a, b, c)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2fm8KVyoyoNh"},"source":["###### **EXERCISE**\n","> Implement:\n","> - Matrix transpose with einsum, in particular assume you have a batch of images of shape $(B, C, H, W)$ and you want to turn it into having shape $(B, H, W, C)$\n","> - Quadratic form with einsum  ($y = v^TMv$)"]},{"cell_type":"markdown","metadata":{"id":"HKMXdwUdRN4U"},"source":["#### 📖 Singleton dimensions\n","\n"," In deep learning it is very common to **add or remove dimensions of size $1$** in a tensor. As we mentioned, this is called **unsqueezing** and **squeezing**, and it occurs often during batch processing, manipulating feature maps, making network layers compatible, and in several other occasions.\n","\n"," It is possible to perform these operations in different ways, feel free to use\n"," whatever is more comfortable to you! Again, **prefer readability to cryptic one-liners** for the sanity of a hypothetical unknown reader or your future self.\n","\n","In the example below, we transform a rank-1 tensor into a rank-2 \"column\", and back to a rank-1:"]},{"cell_type":"code","metadata":{"id":"3DsWB2_iRwTg"},"source":["# Define a rank-1 tensor we will use\n","x = torch.arange(6)\n","print_arr(x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nFqraseqSAhO"},"source":["Transform **`x` into a column tensor** in four different ways.\n","\n","Remember that the shape of a column tensor is in the form: `(rows, 1)`"]},{"cell_type":"code","metadata":{"id":"u-BC2G0TSSfO"},"source":["# 1)\n","# Use the `reshape` or `view` functions\n","\n","y1 = x.reshape(-1, 1)\n","y2 = x.view(-1, 1)\n","\n","print_arr(y1, y2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eMOA51cBPp1i"},"source":["# 2)\n","# Use the specific `unsqueeze` function to unsqueeze a dimension\n","\n","y3 = x.unsqueeze(dim=-1)\n","y4 = x.unsqueeze(dim=1)\n","\n","print_arr(y3, y4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GXkhm2nVN8KZ"},"source":["# 3)\n","# Explicitly index a non-existing dimension with `None`\n","\n","y5 = x[:, None]\n","\n","print_arr(y5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6RF7p0CutPQ6"},"source":["# 4)\n","# Same as before, but do not assume a rank-2 tensor and index the last one.\n","# This approach is useful to write functions that work both for\n","# batched or non-batched data\n","\n","y6 = x[..., None]\n","\n","print_arr(y5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2XBTG4CNTcLf"},"source":["# Now we go back to a rank-1 tensor\n","\n","x1 = y1.reshape(-1)\n","x2 = y2.view(-1)          # Explicity enforce to get a view of the tensors, without copying data\n","x3 = y3.squeeze(dim=-1)\n","x4 = y4.squeeze(dim=1)\n","x5 = y5[:, 0]             # Manually collapse the dimension with an integer indexing\n","x6 = y6[..., 0]\n","\n","print_arr(x1, x2, x3, x4, x5, x6)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nMVrjaXWySWR"},"source":["> **NOTE**\n",">\n","> indexing with `...` means  **keeping all the other dimensions the same**.\n","> Keep in mind that `...` is just a Python singleton object (just as `None`).\n","> Its type is Ellipsis:\n"]},{"cell_type":"code","metadata":{"id":"MNKIfvMTsipK"},"source":["..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BErfK7zVFhAV"},"source":["x = torch.rand(3,3,3)\n","x[:, :, 0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eo3ymGK7FhZS"},"source":["x[..., 0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qKyFGa7B6jXb"},"source":["### Tensor types\n","Pay attention to the tensor types!\n","Several methods are available to convert tensors to different types:"]},{"cell_type":"code","metadata":{"id":"hHIa9x_X6tnE"},"source":["a = torch.rand(3, 3) + 0.5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5swdKvAa6w81"},"source":["a.int()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XQfh53W26x6R"},"source":["a.long()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"22VBQVrG64Qq"},"source":["a.float()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WSdMzMOb6yk0"},"source":["a.double()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rXKThOrW6zQF"},"source":["a.bool()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BLuyxzT_60Bw"},"source":["a.to(torch.double)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sJDsriTC64-e"},"source":["a.to(torch.uint8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_YRWAuTW7Ybn"},"source":["a.bool().int()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2InvGnAtJ3nJ"},"source":["**Pro tip:** Do not try to memorize all the PyTorch API!\n","\n","> Learn to understand what operation should already exist and search for it, when you need it. If it is something common, and it usually is, chances are it already exists.\n","\n","Google, StackOverflow and the docs are your friends!"]},{"cell_type":"markdown","metadata":{"id":"7x0_oylwuIgD"},"source":["### 📖 Einops\n","\n","If you liked the `einsum` operation, have fun with the [einops](https://github.com/arogozhnikov/einops) package! 🚀\n","\n","It is a third-party library, compatible with most frameworks, that brings superpowers to `einsum`. We will not use the `einops` library in the tutorials, however, feel free to read the [docs](https://github.com/arogozhnikov/einops) and use it.\n","\n","![](http://arogozhnikov.github.io/images/einops/einops_video.gif)\n"]},{"cell_type":"markdown","metadata":{"id":"lafVikgz_ypX"},"source":["### Final exercises"]},{"cell_type":"markdown","source":["These final exercises are designed to showcase the elegant solutions of einsum.\n","\n","Feel free to also write down solutions that do _not_ use einsum, but rather with standard tensor manipulation!"],"metadata":{"id":"yKKthCbr_dHf"}},{"cell_type":"markdown","metadata":{"id":"VPeJMqEACs8z"},"source":["\n","#### **EXERCISE 1**\n",">\n","> You are given $b$ images with size $w \\times h$. Each pixel in each image has three color channels, `(r, g, b)`. These images are organized in a tensor $X \\in \\mathbb{R}^{w \\times b \\times c \\times h}$.\n",">\n","> You want to apply a linear trasformation to the color channel of each single image. In particular, you want to :\n","> - **Convert each image into a grey scale image**.\n","> - **Afterthat, transpose the images** to swap the height and width.\n",">\n","> The linear traformation that converts from `(r, g, b)` to grey scale is simply a linear combination of `r`, `g` and `b`. It can be encoded in the following 1-rank tensor $y \\in \\mathbb{R}^3$:"]},{"cell_type":"code","metadata":{"id":"0BRybv63oysl"},"source":["y = torch.tensor([0.2989, 0.5870, 0.1140], dtype=torch.float)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ON5HBjD2oyLi"},"source":["\n","> At the end, you want to obtain a tensor $Z \\in \\mathbb{R}^{b \\times w \\times h}$.\n",">\n","> Write the PyTorch code that performs this operation."]},{"cell_type":"code","metadata":{"id":"If137gBApDcR"},"source":["# Create the input tensors for the exercise\n","# Execute and ignore this cell\n","\n","from skimage import io\n","from skimage.transform import resize\n","\n","size = 100\n","\n","image1 = io.imread('https://upload.wikimedia.org/wikipedia/commons/thumb/6/6f/Earth_Eastern_Hemisphere.jpg/260px-Earth_Eastern_Hemisphere.jpg')\n","image1 = torch.from_numpy(resize(image1, (size, size), anti_aliasing=True)).float()  # Covert  to float type\n","image1 = image1[..., :3]  # remove alpha channel\n","\n","image2 = io.imread('https://upload.wikimedia.org/wikipedia/commons/thumb/b/b4/The_Sun_by_the_Atmospheric_Imaging_Assembly_of_NASA%27s_Solar_Dynamics_Observatory_-_20100819.jpg/628px-The_Sun_by_the_Atmospheric_Imaging_Assembly_of_NASA%27s_Solar_Dynamics_Observatory_-_20100819.jpg')\n","image2 = torch.from_numpy(resize(image2, (size, size), anti_aliasing=True)).float()\n","image2 = image2[..., :3]  # remove alpha channel\n","\n","image3 = io.imread('https://upload.wikimedia.org/wikipedia/commons/thumb/8/80/Wikipedia-logo-v2.svg/1920px-Wikipedia-logo-v2.svg.png')\n","image3 = torch.from_numpy(resize(image3, (size, size), anti_aliasing=True)).float()\n","image3 = image3[..., :3]  # remove alpha channel\n","\n","source_images = torch.stack((image1, image2, image3), dim=0)\n","images = torch.einsum('bwhc -> wbch', source_images)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DGgBC-dkqwVo"},"source":["# Plot source images\n","plot_row_images(source_images)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Flm4DsjMww90"},"source":["# ✏️ your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NwGXAyrVryTz","cellView":"form"},"source":["# @title 👀 Solution\n","\n","\n","# Grey-fy all images together, using the `images` tensor\n","gray_images = torch.einsum('wbch, c -> bwh', (images, y))\n","\n","# What if you want to transpose the images?\n","gray_images_tr = torch.einsum('wbch, c -> bhw', (images, y))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EEWp-NDzsB4V"},"source":["# Plot the gray images\n","plot_row_images(gray_images)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ga_3wk7BPmp6"},"source":["# Plot the gray transposed images\n","plot_row_images(gray_images_tr)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oF6FdNroYMqn"},"source":["#### **EXERCISE 2**\n",">\n","> Given $k$ points organized in a tensor $X \\in \\mathbb{R}^{k \\times 2}$ apply a reflection along the $y$ axis as a linear transformation.\n",""]},{"cell_type":"code","metadata":{"id":"q_d9KnJ5Y3e0"},"source":["# Define some points in R^2\n","x = torch.arange(100, dtype=torch.float)\n","y = x ** 2\n","\n","# Define some points in R^2\n","data = torch.stack((x, y), dim=0).t()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h0_JB4C1Y2vm"},"source":["px.scatter(x = data[:, 0].numpy(), y = data[:, 1].numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c1Xt5XEkDYvB"},"source":["# ✏️ your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eWCEwmIfaebY","cellView":"form"},"source":["# @title 👀 Solution\n","\n","\n","# Define a matrix that encodes a linear transformation\n","S = torch.tensor([[-1, 0],\n","                  [ 0, 1]], dtype=torch.float)\n","\n","# Apply the linear transformation: the order is important\n","new_data = torch.einsum('nk, dk -> nd', (data, S))\n","\n","# Double check yourself:\n","# The linear transformation correctly maps the basis vectors!\n","S @ torch.tensor([[0],\n","                  [1]], dtype=torch.float)\n","S @ torch.tensor([[1],\n","                  [0]], dtype=torch.float)\n","\n","# Check if at least the shape is correct\n","new_data.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5H7VEJFXbaMb"},"source":["# Plot the new points\n","px.scatter(x = new_data[:, 0].numpy(), y = new_data[:, 1].numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g1tHmuIBM9ka"},"source":["#### **EXERCISE 3**\n",">\n",">  You are given $b$ images with size $w \\times h$. Each pixel in each image has `(r, g, b)` channels. These images are organized in a tensor $X \\in \\mathbb{R}^{w \\times b \\times c \\times h}$, i.e. the same tensor as in the exercise 1.\n",">\n","> You want to swap the `red` color with the `blue` color, and decrease the intensity of the `green` by half.\n",">\n","> Perform the transformation on all the images simultaneously."]},{"cell_type":"code","metadata":{"id":"lppGxeMSO0c8"},"source":["images.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"POWStC54w2ZZ"},"source":["# ✏️ your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VE2xc7i_ORzg","cellView":"form"},"source":["# @title 👀 Solution\n","\n","\n","# Define the linear transformation to swap the blue and red colors\n","# and half the green\n","S = torch.tensor([[ 0, 0, 1],\n","                  [ 0, .5, 0],\n","                  [ 1, 0, 0]], dtype=torch.float)\n","\n","# Apply the linear transformation to the color channel!\n","rb_images = torch.einsum('wbch, dc -> bwhd', (images, S))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zdfYOMBOxjv"},"source":["plot_row_images(rb_images)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qLCQReiBPLqd"},"source":["#### 📖 **EXERCISE 4**\n",">\n",">  You are given $b$ images with size $w \\times h$. Each pixel in each image has `(r, g, b)` colors. These images are organized in a tensor $X \\in \\mathbb{R}^{w \\times b \\times c \\times h}$, i.e. the same tensor as exercise 1 and 3.\n",">\n","> You want to **convert each image into a 3D point cloud**:\n","> - the `(x, y)` coordinates of each point in the point cloud are the **indices** of the pixels in the original image\n","> - the `z` coordinate of each point in the point cloud is the $L_2$ norm of the color of the corresponding pixel, multiplied by $10$\n",">\n","> *Hint*: you may need some other PyTorch function, search the docs!"]},{"cell_type":"code","metadata":{"id":"Sk-O_iHgSlbX","cellView":"form"},"source":["# @title 👀 Solution\n","\n","\n","# Just normalize the tensor into the common form [batch, width, height, colors]\n","imgs = torch.einsum('wbch -> bwhc', images)\n","imgs.shape\n","\n","# The x, y coordinate of the point cloud are all the possible pairs of indices (i, j)\n","row_indices = torch.arange(imgs.shape[1], dtype=torch.float)\n","col_indices = torch.arange(imgs.shape[2], dtype=torch.float)\n","xy = torch.cartesian_prod(row_indices , col_indices)\n","\n","# Compute the L2 norm for each pixel in each image\n","depth = imgs.norm(p=2, dim = -1)\n","# depth = torch.einsum('bwhc, bwhc -> bwh', (imgs, imgs)) ** (1/2)\n","\n","# For every pair (i, j), retrieve the L2 norm of that pixel\n","z = depth[:, xy[:, 0].long(), xy[:, 1].long()] * 10\n","\n","# Adjust the dimensions, repeat and concatenate accordingly\n","xy = xy.repeat(imgs.shape[0], 1, 1)  # x,y coordinates are constant for the three images\n","clouds = torch.cat((xy, z[..., None] ), dim= 2)\n","\n","# Three images, 10000 points, each point with coordinates x,y,z in 3D\n","clouds.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f1S0OYtiZgT_"},"source":["# Utility function\n","# Execute and ignore this cell\n","\n","from typing import Union\n","\n","def plot_3d_point_cloud(cloud: Union[torch.Tensor, np.ndarray]) -> None:\n","  \"\"\" Plot a single 3D point cloud\n","\n","  :param cloud: tensor with shape [number of points, coordinates]\n","  \"\"\"\n","  import pandas as pd\n","  df = pd.DataFrame(np.asarray(cloud), columns=['x', 'y', 'z'])\n","  fig = px.scatter_3d(df, x=df.x, y=df.y, z=df.z, color=df.z, opacity=1, range_z=[0, 30])\n","  fig.update_layout({'scene_aspectmode': 'data', 'scene_camera':  dict(\n","          up=dict(x=0., y=0., z=0.),\n","          eye=dict(x=0., y=0., z=3.)\n","      )})\n","  fig.update_traces(marker=dict(size=3,),\n","                    selector=dict(mode='markers'))\n","  _ = fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BlKzABIKm9UZ"},"source":["plot_3d_point_cloud(clouds[0, ...])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n5Jm-zYSbQYU"},"source":["plot_3d_point_cloud(clouds[1, ...])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TH0CITRgZnyZ"},"source":["plot_3d_point_cloud(clouds[2, ...])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ivMykCiurNH"},"source":[],"execution_count":null,"outputs":[]}]}